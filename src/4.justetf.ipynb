{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functions import *\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "os.chdir(Path.cwd().parents[0]) # Set path as if it was in root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/preprocessed/'\n",
    "fund_path = root + f'fundamentals_{datetime.now().strftime('%Y-%m')}.csv'\n",
    "\n",
    "fund_df = load(fund_path)\n",
    "fund_df['funds_date'] = pd.to_datetime(fund_df['funds_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_etf_profile(isin):\n",
    "    url = f\"https://www.justetf.com/en/etf-profile.html?isin={isin}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    data = {'isin': isin}\n",
    "\n",
    "    etf_title_tag = soup.find('h1', id='etf-title')\n",
    "    data['name'] = etf_title_tag.text.strip() if etf_title_tag else None\n",
    "    \n",
    "    # Get WKN and Ticker\n",
    "    wkn_tag = soup.find('span', id='etf_identifier_1')\n",
    "    data['wkn'] = wkn_tag.text.strip() if wkn_tag else None\n",
    "    ticker_tag = soup.find('span', id='etf_identifier_2')\n",
    "    data['ticker'] = ticker_tag.text.strip() if ticker_tag else None\n",
    "\n",
    "    # Scrape Labels (e.g., \"Savings plan\", \"ETF\")\n",
    "    tags_list = []\n",
    "    tags_container = soup.find('div', class_='m-xs-sep-m')\n",
    "    if tags_container:\n",
    "        tags = tags_container.find_all('span', class_='label')\n",
    "        # Extract clean text from each tag\n",
    "        tags_list = [tag.get_text(strip=True) for tag in tags]\n",
    "    data['tags'] = tags_list\n",
    "\n",
    "    # Scrape the Main Overview Section\n",
    "    # This replaces the failing get_value_from_overview() function with a more robust method.\n",
    "    overview_section = soup.find('div', class_='data-overview')\n",
    "    if overview_section:\n",
    "        # Find all pairs of labels and values\n",
    "        for item in overview_section.find_all('div', class_='d-flex-column'):\n",
    "            label_tag = item.find('div', class_='vallabel')\n",
    "            value_tag = item.find('div', class_='val')\n",
    "            if label_tag and value_tag:\n",
    "                # Clean up the label to use as a dictionary key\n",
    "                label_key = label_tag.get_text(strip=True).lower().replace(' ', '_')\n",
    "                value = value_tag.get_text(separator=' ', strip=True)\n",
    "                data[label_key] = value\n",
    "\n",
    "    # Scrape Data from the \"Basics\" Table (Corrected Logic)\n",
    "    basics_section = soup.find('div', id='basics')\n",
    "    if basics_section:\n",
    "        table = basics_section.find('table', class_='etf-data-table')\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                # A valid row should have two cells: a label and a value\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) == 2:\n",
    "                    label_tag = cells[0]\n",
    "                    value_tag = cells[1] # Correctly select the second cell for the value\n",
    "                    \n",
    "                    label = label_tag.text.strip().lower().replace(' ', '_').replace('/', '_')\n",
    "                    \n",
    "                    # The value is often nested inside another div within the td\n",
    "                    value_div = value_tag.find('div', class_='val') or value_tag.find('span', class_='val2')\n",
    "                    value = value_div.text.strip() if value_div else value_tag.text.strip()\n",
    "\n",
    "                    # Add specific key info to our data dictionary\n",
    "                    if 'fund_currency' in label:\n",
    "                        data['fund_currency'] = value\n",
    "                    elif 'volatility_1_year' in label:\n",
    "                        data['volatility_1y'] = value\n",
    "                    elif 'fund_domicile' in label:\n",
    "                        data['domicile'] = value\n",
    "                    elif 'fund_provider' in label:\n",
    "                        data['provider'] = value\n",
    "                        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_path = root + f'justetf_{datetime.now().strftime('%Y-%m')}.csv'\n",
    "try:\n",
    "    scraped_df = load(scraped_path)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "scraped_data = []\n",
    "missing = fund_df[~fund_df['isin'].isin(scraped_df['isin'])]['isin']\n",
    "for isin in tqdm(missing, total=len(missing)):\n",
    "    try:\n",
    "        result = scrape_etf_profile(isin)\n",
    "        scraped_data.append(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    sleep(2)\n",
    "\n",
    "if 'scraped_df' in globals():\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "    scraped_df = pd.concat([scraped_df, df], ignore_index=True).drop_duplicates(subset='isin')\n",
    "else:\n",
    "    scraped_df = pd.DataFrame(scraped_data)\n",
    "scraped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_path = root + f'justetf_{datetime.now().strftime('%Y-%m')}.csv'\n",
    "scraped_df.to_csv(scraped_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
