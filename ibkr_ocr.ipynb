{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import traceback\n",
    "import ast\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from rapidfuzz import fuzz\n",
    "import gc\n",
    "import re\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import platform\n",
    "if platform.system() == \"Darwin\":\n",
    "    from AppKit import NSWorkspace, NSApplicationActivateIgnoringOtherApps\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up functions\n",
    "def extract_text(ocr, screenshot):\n",
    "    try:\n",
    "        result = ocr.ocr(screenshot, cls=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        result = [None]\n",
    "\n",
    "    text = []\n",
    "    if result[0]:\n",
    "        for idx in range(len(result)):\n",
    "            res = result[idx]\n",
    "            for line in res:\n",
    "                if line[-1][-1] > 0.85:\n",
    "                    text.append(line[-1][0].replace(' ',''))\n",
    "    # print(result)\n",
    "    return text\n",
    "\n",
    "def scroll(amount, attempts=2):\n",
    "    SCROLL_TOP = 600\n",
    "    SCROLL_BOT = 550\n",
    "    \n",
    "    before = pyautogui.screenshot(region=(0, 25, 1919, 1054))\n",
    "    before = np.array(before)\n",
    "    for _ in range(attempts):\n",
    "        rand_int = random.randint(SCROLL_BOT, SCROLL_TOP)\n",
    "        pyautogui.scroll(amount, rand_int, rand_int)\n",
    "        after = pyautogui.screenshot(region=(0, 25, 1919, 1054))\n",
    "        after = np.array(after)\n",
    "\n",
    "        if not np.array_equal(before, after):\n",
    "            return\n",
    "        \n",
    "    # raise Exception(f'scroll() failed')\n",
    "        \n",
    "def wait(seconds=5, interval=0.5):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "        screenshot = pyautogui.screenshot(region=(10, 280, 440, 200))\n",
    "        screenshot = np.array(screenshot)\n",
    "        screenshot = screenshot[:, :, :3]\n",
    "\n",
    "        if np.any(np.all(screenshot == (247, 247, 247), axis=-1)):\n",
    "            return\n",
    "        sleep(interval)\n",
    "    raise Exception('wait() text never loaded')\n",
    "    \n",
    "def select_tab(name, seconds=5):\n",
    "    try:\n",
    "        scroll(999)\n",
    "        tab = pyautogui.locateCenterOnScreen(f'assets/{name}/tab_label.png', confidence=0.9)\n",
    "        pyautogui.click(tab)\n",
    "        wait(seconds)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "def agree():\n",
    "    while True:\n",
    "        try:\n",
    "            agree = pyautogui.locateOnScreen(\"assets/fund_setup/agree.png\", confidence=0.9)\n",
    "            pyautogui.click(agree)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "\n",
    "def clear_modals():\n",
    "    while True:\n",
    "        try:\n",
    "            log_off_timer = pyautogui.locateOnScreen(\"assets/fund_setup/log_off_timer.png\", confidence=0.9)\n",
    "            left_x = log_off_timer.left + 34\n",
    "            center_y = log_off_timer.top + log_off_timer.height // 2\n",
    "            pyautogui.click(left_x, center_y)\n",
    "        except Exception:\n",
    "            break\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            search_error = pyautogui.locateOnScreen(\"assets/fund_setup/search_error.png\", confidence=0.9)\n",
    "            left_x = search_error.left + 25\n",
    "            center_y = search_error.top + search_error.height // 2\n",
    "            pyautogui.click(left_x, center_y)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "def select_exchange():\n",
    "    while True:\n",
    "        try:\n",
    "            pyautogui.locateOnScreen(\"assets/fund_setup/contract_selection.png\", confidence=0.9)\n",
    "            pyautogui.press(\"up\")\n",
    "            pyautogui.press(\"enter\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "def switch_to_app(app_name='Trader Workstation'):\n",
    "    workspace = NSWorkspace.sharedWorkspace()\n",
    "    apps = workspace.runningApplications()\n",
    "    for app in apps:\n",
    "        if app.localizedName() == app_name:\n",
    "            app.activateWithOptions_(NSApplicationActivateIgnoringOtherApps)\n",
    "            break\n",
    "\n",
    "def exit_search():\n",
    "    pyautogui.press(\"enter\", presses=2, interval=0.3)\n",
    "    if select_exchange():\n",
    "        exchange_bug = True\n",
    "    else:\n",
    "        exchange_bug = False\n",
    "    agree()\n",
    "\n",
    "    # Redundant check in case a press fails\n",
    "    pyautogui.press(\"enter\", presses=1, interval=0.3)\n",
    "    if not exchange_bug and select_exchange():\n",
    "        exchange_bug = True\n",
    "    else:\n",
    "        exchange_bug = False\n",
    "    agree()\n",
    "    clear_modals()\n",
    "    return exchange_bug\n",
    "\n",
    "def check_search_results(ocr, row, screenshot, screenshot_left, screenshot_top, buffer, width=800):\n",
    "    matches, HEIGHT, adjustable_height, max_adjustable_height, top, text_detected = [], 21, 21, 42, buffer, False\n",
    "\n",
    "    screenshot_array = np.array(screenshot)\n",
    "    target_color = [64, 64, 64, 255]    \n",
    "    replacement_color = [109, 111, 113, 255]\n",
    "    mask = np.all(screenshot_array == target_color, axis=-1)\n",
    "    screenshot_array[mask] = replacement_color\n",
    "    \n",
    "    while True:\n",
    "        # display(Image.fromarray(screenshot_array[top:top+adjustable_height]))\n",
    "        text_list = extract_text(ocr, screenshot_array[top:top+adjustable_height])\n",
    "        # print(text_list, adjustable_height)\n",
    "        # print(row['symbol'], row['validExchanges'])\n",
    "        \n",
    "        if not text_list:\n",
    "            if text_detected:\n",
    "                pass\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if len(text_list) > 1:\n",
    "            search_symbol = text_list[0]\n",
    "            row_symbol = str(row['symbol'])\n",
    "            try:\n",
    "                int(row_symbol)\n",
    "                confidence = 90\n",
    "            except Exception:\n",
    "                confidence = 75\n",
    "\n",
    "            if (len(search_symbol) == len(row_symbol)) and fuzz.partial_ratio(search_symbol, row_symbol) >= confidence:\n",
    "                search_exchange = text_list[1:]\n",
    "                search_exchange = [exchange for exchange in search_exchange if '(' in exchange]\n",
    "                position = (screenshot_left + (width / 2), (screenshot_top + top) + adjustable_height / 2)\n",
    "                matches.append((search_exchange, search_symbol, position))\n",
    "            # Move to the next row\n",
    "            top += HEIGHT + (adjustable_height - HEIGHT)//2\n",
    "            adjustable_height = HEIGHT\n",
    "            text_detected = False\n",
    "        else:\n",
    "            # Adjust region for better OCR\n",
    "            top -= 1\n",
    "            adjustable_height += 2\n",
    "            text_detected = True\n",
    "            if adjustable_height > max_adjustable_height:\n",
    "                top += HEIGHT + (adjustable_height - HEIGHT)//2\n",
    "                adjustable_height = HEIGHT\n",
    "                text_detected = False\n",
    "\n",
    "    # print(matches)\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            for ex in match[0]:\n",
    "                if fuzz.partial_ratio(row['exchange'], ex) >= 80:\n",
    "                    return ex, match[1], match[2]\n",
    "        for match in matches:\n",
    "            for ex in match[0]:\n",
    "                if fuzz.partial_ratio(row['primaryExchange'], ex) >= 80:\n",
    "                    return ex, match[1], match[2]\n",
    "                \n",
    "        valid_exchanges = row['validExchanges'].split(',') if row['validExchanges'] else []\n",
    "        for match in matches:\n",
    "            for ex in match[0]:\n",
    "                for valid_exchange in valid_exchanges:\n",
    "                    if fuzz.partial_ratio(valid_exchange.strip(), ex) >= 80:\n",
    "                        return ex, match[1], match[2]\n",
    "        \n",
    "def check_search_table(buffer, width=800, seconds=8):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    i = 0\n",
    "    while datetime.now() - start < timeout:\n",
    "        try:\n",
    "            search = pyautogui.locateOnScreen(f'assets/fund_setup/search{i}.png', confidence=0.8)\n",
    "            break\n",
    "        except Exception:\n",
    "            i = (i + 1) % 3\n",
    "    left = search.left\n",
    "    top = search.top + search.height - buffer # add some buffer for OCR region adjustments in check_search_results()\n",
    "    try:\n",
    "        search_bottom = pyautogui.locateOnScreen(f'assets/fund_setup/search_bottom.png', confidence=0.9)\n",
    "        height = (search_bottom.top - top) + search_bottom.height + (buffer - 21)\n",
    "    except Exception:\n",
    "        print('set height')\n",
    "        height = 300\n",
    "\n",
    "    next_row = buffer + 1 # +1 to make sure that we're detecting the next row\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot_array = np.array(screenshot)\n",
    "    if screenshot_array[next_row][-1].tolist() == [64, 64, 64, 255]:\n",
    "        return screenshot, left, top, buffer\n",
    "    elif screenshot_array[next_row][-1].tolist() == [109, 111, 113, 255]:\n",
    "        raise Exception('search_etf() did not find the correct symbol')\n",
    "    else:\n",
    "        return check_search_table(buffer, seconds=seconds)\n",
    "        \n",
    "def search_eft(ocr, row, wait_time=5):\n",
    "    scroll(999)\n",
    "    pyautogui.press(\"esc\")\n",
    "    pyautogui.click((1880,100), interval=0.2)\n",
    "\n",
    "    pyautogui.click(positions['search_box'], interval=0.2)\n",
    "    pyautogui.write(row['longName'])\n",
    "    pyautogui.press(\"enter\")\n",
    "\n",
    "    buffer = 15\n",
    "    screenshot, left, top, buffer = check_search_table(buffer, seconds=wait_time)\n",
    "    \n",
    "    exchange, symbol, row_position = check_search_results(ocr, row, screenshot, left, top, buffer + 1) # +1 to center the row text in frame. \n",
    "    if row_position:\n",
    "        pyautogui.click(row_position)\n",
    "        exchange_bug = exit_search()\n",
    "        return exchange, symbol, exchange_bug\n",
    "    else:\n",
    "        clear_modals()\n",
    "        raise Exception('search_etf() did not find the correct symbol')\n",
    "    \n",
    "def quick_search_etf(row, count=None, name=None):\n",
    "    pyautogui.press(\"esc\")\n",
    "    pyautogui.click((1880,100), interval=0.2)\n",
    "    pyautogui.click(positions['search_box'], interval=0.2)\n",
    "    if count:\n",
    "        pyautogui.press(\"delete\", presses=count)\n",
    "        pyautogui.press(\"backspace\", presses=count)\n",
    "    if name:\n",
    "        pyautogui.write(name)\n",
    "    else:\n",
    "        pyautogui.write(row['symbol'])\n",
    "\n",
    "    exchange_bug = exit_search()\n",
    "    return exchange_bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_profile(text_list):\n",
    "    headings = ['TotalExpenseRatio', 'TotalNetAssets', 'BenchmarkIndex', 'Domicile', 'MarketGeoFocus', 'MarketCapFocus', 'FundCategory']\n",
    "    current_label, current_values, labels, values = None, [], [], []\n",
    "    threshold = 80\n",
    "\n",
    "    for item in text_list:\n",
    "        matches = [(heading, fuzz.partial_ratio(item, heading)) for heading in headings]\n",
    "        best_match = max(matches, key=lambda x: x[1])\n",
    "\n",
    "        if best_match[1] >= threshold and (current_label != best_match[0]):\n",
    "            if current_label:\n",
    "                labels.append(current_label)\n",
    "                values.append(' '.join(current_values))\n",
    "                current_values = []\n",
    "            current_label = best_match[0]\n",
    "        else:\n",
    "            current_values.append(item)\n",
    "\n",
    "    if current_label:\n",
    "        labels.append(current_label)\n",
    "        values.append(' '.join(current_values))\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_profile(ocr):\n",
    "    profile = pyautogui.locateOnScreen(\"assets/overview/profile.png\", confidence=0.9)\n",
    "    left = profile.left\n",
    "    top = profile.top + profile.height\n",
    "    lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.9)\n",
    "    width = 600\n",
    "    height = lipper.top - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    scroll(-height/8)\n",
    "    if text_list:\n",
    "        return process_profile(text_list)\n",
    "    else:\n",
    "        raise Exception('skip')\n",
    "    \n",
    "def check_title(ocr, title, seconds=5, interval=1):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "\n",
    "        # Check for white text\n",
    "        screenshot = pyautogui.screenshot(region=(25, 100, 65, 25))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_color = (247, 247, 247, 255)\n",
    "        if np.any(np.all(screenshot == text_color, axis=-1)):\n",
    "            \n",
    "            # Check text match\n",
    "            screenshot = pyautogui.screenshot(region=(25, 100, 480, 60))\n",
    "            screenshot = np.array(screenshot)\n",
    "            text = extract_text(ocr, screenshot)\n",
    "            if fuzz.partial_ratio(text[0][:len(title)].upper(), title.upper()) >= 85:\n",
    "                return text[0]\n",
    "            else:\n",
    "                return\n",
    "        sleep(interval)\n",
    "\n",
    "def check_tradable(seconds=5, interval=0.5):\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    start = datetime.now()\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "\n",
    "        # Check for white text\n",
    "        screenshot = pyautogui.screenshot(region=(25, 100, 65, 25))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_color = (247, 247, 247, 255)\n",
    "        if np.any(np.all(screenshot == text_color, axis=-1)):\n",
    "\n",
    "            # Check for nt sign\n",
    "            sleep(interval)\n",
    "            screenshot = pyautogui.screenshot(region=(25, 125, 300, 100))\n",
    "            screenshot = np.array(screenshot)\n",
    "            nt_sign_color = (240, 71, 80, 255)\n",
    "            if np.any(np.all(screenshot == nt_sign_color, axis=-1)):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "def process_holding_types(text_list):\n",
    "    # Assumes text is identified from left to right, and top to bottom\n",
    "    for i, element in enumerate(text_list):\n",
    "        if element.strip().isupper():\n",
    "            text_list = text_list[:i]\n",
    "            break\n",
    "\n",
    "    last_label, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            labels.append(last_label)\n",
    "            values.append(item)\n",
    "            last_label = None\n",
    "        else:\n",
    "            if last_label:\n",
    "                labels.append(last_label)\n",
    "                values.append(None)\n",
    "            last_label = item\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_holding_types(ocr):\n",
    "    holdings = pyautogui.locateOnScreen(\"assets/overview/holdings.png\", confidence=0.9)\n",
    "    left = holdings.left\n",
    "    top = holdings.top + holdings.height\n",
    "    dividends = pyautogui.locateOnScreen(\"assets/overview/dividends.png\", confidence=0.9)\n",
    "    width = 600\n",
    "    height = dividends.top - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    scroll(-height / 8)\n",
    "    if len(text_list) > 1:\n",
    "        return process_holding_types(text_list)\n",
    "    else:\n",
    "        raise Exception('skip')\n",
    "\n",
    "def process_dividends(text_list):\n",
    "    # Assumes text is identified from left to right, and top to bottom\n",
    "    labels, values, label_indicator, value_indicator = [], [], False, False\n",
    "    \n",
    "    for item in text_list:\n",
    "        if fuzz.partial_ratio(item, 'Div.YieldTTM') >= 90:\n",
    "            label_indicator = True\n",
    "        if label_indicator:\n",
    "            if item[-1] == '%' or item == 'Unknown':\n",
    "                value_indicator = True\n",
    "                label_indicator = False\n",
    "                values.append(item)\n",
    "            else:\n",
    "                labels.append(item)\n",
    "        elif value_indicator:\n",
    "            values.append(item)\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_dividends(ocr):\n",
    "    try:\n",
    "        dividends = pyautogui.locateOnScreen(\"assets/overview/dividends.png\", confidence=0.9)\n",
    "        left = dividends.left\n",
    "        top = dividends.top + dividends.height\n",
    "        width = 600\n",
    "        height = 200\n",
    "\n",
    "        screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "        screenshot = np.array(screenshot)\n",
    "\n",
    "        text_list = extract_text(ocr, screenshot)\n",
    "        if 'IndustryAverage' not in text_list:\n",
    "            return process_dividends(text_list)\n",
    "    except Exception as e:\n",
    "        raise Exception(f'extract_dividends() {e}')\n",
    "    \n",
    "def extract_style():\n",
    "    style = pyautogui.locateOnScreen(\"assets/overview/style_matrix.png\", confidence=0.9)\n",
    "    left = style.left + style.width + 70\n",
    "    width = 280\n",
    "    height = 172\n",
    "    lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.9)\n",
    "    top = lipper.top - height - 113\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "    highlight_colors = [\n",
    "        (29, 51, 88, 255),\n",
    "        (255, 255, 255, 255),\n",
    "        (41, 112, 234, 255)\n",
    "    ]\n",
    "    background_color = (24, 24, 24, 255)\n",
    "\n",
    "    color_matches = np.zeros(screenshot.shape[:-1], dtype=bool)\n",
    "    for color in highlight_colors:\n",
    "        color_matches |= np.all(screenshot == color, axis=-1)\n",
    "\n",
    "    if np.any(color_matches):\n",
    "        styles = []\n",
    "        rows = ['large', 'multi', 'mid', 'small']\n",
    "        columns = ['value', 'core', 'growth']\n",
    "        for i, row in enumerate(rows):\n",
    "            row_step_px = round(height / (len(rows) - 1)) - 1 # First -1 to get the num of internal boundaries == num of areas - 1. Second -1 to avoid index overflow\n",
    "            for j, col in enumerate(columns):\n",
    "                col_step_px = round(width / (len(columns) - 1)) - 1\n",
    "                pixel = screenshot[row_step_px * i][col_step_px * j].tolist()\n",
    "                styles.append((f'{row}-{col}', pixel != list(background_color)))\n",
    "    \n",
    "        return styles\n",
    "\n",
    "def process_lipper(text_index, screenshot, width, height):\n",
    "    bg_color = [24, 24, 24, 255]\n",
    "    missing_color = [0, 0, 0, 255]\n",
    "    row_idx = 16 + round(35 * text_index)\n",
    "    for j in range(5):\n",
    "        col_step_px = round(width/5) - 1\n",
    "        pixel = screenshot[row_idx][col_step_px * (j+1)].tolist()\n",
    "        if pixel == bg_color or pixel == missing_color:\n",
    "            return j + 1\n",
    "\n",
    "def extract_lipper(ocr):\n",
    "    try:\n",
    "        lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.9)\n",
    "        left = lipper.left\n",
    "        top = lipper.top + lipper.height\n",
    "        holdings = pyautogui.locateOnScreen(\"assets/overview/holdings.png\", confidence=0.9)\n",
    "        lipper_width = 300\n",
    "        height = holdings.top - top\n",
    "\n",
    "        screenshot = pyautogui.screenshot(region=(left, top, lipper_width, height))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_list = extract_text(ocr, screenshot)\n",
    "        if text_list:\n",
    "            width = 285\n",
    "            screenshot = pyautogui.screenshot(region=(left+lipper_width+24, top+12, width, height-12))\n",
    "            screenshot = np.array(screenshot)\n",
    "            \n",
    "            lipper = []\n",
    "            for i, label in enumerate(text_list):\n",
    "                value = process_lipper(i, screenshot, width, 34)\n",
    "                lipper.append((label, value))\n",
    "            scroll(-height/10)\n",
    "            return lipper\n",
    "        scroll(-height/10)\n",
    "    except Exception as e:\n",
    "        raise Exception(f'extract_dividends() {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding functions\n",
    "def show_more(type=1):\n",
    "    try:\n",
    "        if type != 1:\n",
    "            show_more = pyautogui.locateCenterOnScreen(\"assets/holdings/show_more2.png\", confidence=0.9)\n",
    "        else:\n",
    "            show_more = pyautogui.locateCenterOnScreen(\"assets/holdings/show_more.png\", confidence=0.9)\n",
    "        pyautogui.click(show_more)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def process_top10(text_list):\n",
    "    # Assumes text is identified from left to right, and top to bottom\n",
    "    index, current_labels, labels , values = True, [], [], []\n",
    "\n",
    "    for item in text_list:\n",
    "        if index and len(item) <= 2 and not item.endswith('%'):\n",
    "            index = False \n",
    "        elif is_numerical(item) and item.endswith('%'):\n",
    "            labels.append('-'.join(current_labels))\n",
    "            values.append(item)\n",
    "            current_labels = []\n",
    "            index = True\n",
    "        else:\n",
    "            current_labels.append(item)\n",
    "            index = False \n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_top10(ocr):    \n",
    "    top10 = pyautogui.locateOnScreen(\"assets/holdings/top10.png\", confidence=0.9)\n",
    "    left = top10.left\n",
    "    top = top10.top + top10.height\n",
    "    width = 626\n",
    "    height = 455\n",
    "\n",
    "    return capture_text(ocr, process_top10, left, top, width, height)\n",
    "\n",
    "def process_industry(text_list): # Industry displays labels, value pairs backwards, so ocr reads them backwards\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            if last_value:\n",
    "                labels.append(None)\n",
    "                values.append(last_value)\n",
    "            last_value = item\n",
    "        else:\n",
    "            labels.append(item)\n",
    "            values.append(last_value)\n",
    "            last_value = None\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def process_holding_tables(text_list):\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        value = re.sub(r'[^\\d.%]', '', item)\n",
    "        if is_numerical(value):\n",
    "            labels.append(last_value)\n",
    "            values.append(value)\n",
    "            last_value = None\n",
    "        else:\n",
    "            if last_value:\n",
    "                labels.append(last_value)\n",
    "                values.append(None)\n",
    "            last_value = item\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def process_bonds(text_list):\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            labels.append(last_value)\n",
    "            values.append(item)\n",
    "            last_value = None\n",
    "        else:\n",
    "            if last_value:\n",
    "                labels.append(last_value)\n",
    "                values.append(None)\n",
    "            last_value = item\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_industry(ocr):\n",
    "    show_more()\n",
    "    industry = pyautogui.locateOnScreen(\"assets/holdings/industry.png\", confidence=0.9)\n",
    "    scroll(-(industry.height*3/4))\n",
    "\n",
    "    industry = pyautogui.locateOnScreen(\"assets/holdings/industry.png\", confidence=0.9)\n",
    "    left = industry.left + 40\n",
    "    top = industry.top + industry.height\n",
    "    width = 550\n",
    "    try:\n",
    "        show_less = pyautogui.locateOnScreen(\"assets/holdings/show_less.png\", confidence=0.9)\n",
    "        height = show_less.top - top\n",
    "    except Exception:\n",
    "        height = 450\n",
    "\n",
    "    return capture_text(ocr, process_industry, left, top, width, height)\n",
    "\n",
    "def extract_country(ocr):\n",
    "    country = pyautogui.locateOnScreen(\"assets/holdings/country.png\", confidence=0.9)\n",
    "    scroll(-(country.top/15))\n",
    "    show_more(2)\n",
    "    country = pyautogui.locateOnScreen(\"assets/holdings/country.png\", confidence=0.9)\n",
    "    left = country.left + 50\n",
    "    top = country.top + country.height\n",
    "    width = 460\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    height = currency.top - top\n",
    "\n",
    "    return capture_text(ocr, process_holding_tables, left, top, width, height)\n",
    "\n",
    "def extract_currency(ocr):\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    scroll(-(currency.top/20))\n",
    "    show_more(2)\n",
    "    scroll(-(currency.top/50), 1)\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    left = currency.left + 50\n",
    "    top = currency.top + currency.height\n",
    "    width = 460\n",
    "    try:\n",
    "        debtor = pyautogui.locateOnScreen(\"assets/holdings/debtor_quality.png\", confidence=0.9)\n",
    "        height = debtor.top - top\n",
    "    except Exception:\n",
    "        height = BOTTOM - top\n",
    "\n",
    "    return capture_text(ocr, process_holding_tables, left, top, width, height)\n",
    "\n",
    "# Resize function\n",
    "def capture_text(ocr, function, left, top, width, height):\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    if text_list:\n",
    "        try:\n",
    "            return function(text_list)\n",
    "        except:\n",
    "            expand_px = 4\n",
    "            screenshot = screenshot = pyautogui.screenshot(region=(left - expand_px, top - expand_px, width + expand_px*2, height + expand_px*2))\n",
    "            screenshot = np.array(screenshot)\n",
    "            text_list = extract_text(ocr, screenshot)\n",
    "            if text_list:\n",
    "                return function(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bond functions\n",
    "def extract_debtors(ocr, name):\n",
    "    scroll(-99, 1)\n",
    "    debtor = pyautogui.locateOnScreen(f\"assets/holdings/{name}.png\", confidence=0.9)\n",
    "    left = debtor.left\n",
    "    top = debtor.top + debtor.height\n",
    "    width = 405\n",
    "    height = BOTTOM - top\n",
    "\n",
    "    return capture_text(ocr, process_bonds, left, top, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamentals functions\n",
    "def extract_fundamentals_text(ocr, screenshot):\n",
    "    # display(Image.fromarray(screenshot))\n",
    "    try:\n",
    "        results = ocr.ocr(screenshot, cls=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        results = [None]\n",
    "\n",
    "    text_list = []\n",
    "    if results and results[0]:\n",
    "        for res in results:\n",
    "            for line in res:\n",
    "                bbox, (text, conf) = line[0], line[-1]\n",
    "                if conf > 0.85:\n",
    "                    text_list.append({\n",
    "                        'text': text.replace(' ', ''),\n",
    "                        'bbox': bbox,\n",
    "                        'conf': conf\n",
    "                    })\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def calculate_value_crop(label_bbox, screenshot, offset=5, expansion=0):\n",
    "    \"\"\"\n",
    "    Given a label's bounding box, calculates a region where its value should be.\n",
    "    The region is expanded by 'expansion' pixels on all sides.\n",
    "    \"\"\"\n",
    "    # Extract coordinates from label_bbox (assumed to be list of 4 points)\n",
    "    x_coords = [pt[0] for pt in label_bbox]\n",
    "    y_coords = [pt[1] for pt in label_bbox]\n",
    "    label_left, label_top = min(x_coords), min(y_coords)\n",
    "    label_right, label_bottom = max(x_coords), max(y_coords)\n",
    "    \n",
    "    # Initial value region: to the right of the label with a small offset.\n",
    "    initial_value_left = label_right + offset\n",
    "    initial_value_top = label_top\n",
    "    screenshot_width = screenshot.shape[1]\n",
    "    initial_value_width = screenshot_width - initial_value_left\n",
    "    initial_value_height = label_bottom - label_top\n",
    "\n",
    "    # Expand the region by 'expansion' pixels on all sides.\n",
    "    new_x = max(initial_value_left, 0)\n",
    "    new_y = max(initial_value_top - expansion, 0)\n",
    "    new_width = initial_value_width\n",
    "    new_height = initial_value_height + 2 * expansion\n",
    "\n",
    "    # Ensure the region stays within the screenshot boundaries.\n",
    "    if new_x + new_width > screenshot.shape[1]:\n",
    "        new_width = screenshot.shape[1] - new_x\n",
    "    if new_y + new_height > screenshot.shape[0]:\n",
    "        new_height = screenshot.shape[0] - new_y\n",
    "\n",
    "    return (int(new_x), int(new_y), int(new_width), int(new_height))\n",
    "\n",
    "\n",
    "def detect_value_with_expansion(ocr, screenshot, label_bbox, initial_offset=5, max_expansion=49):\n",
    "    \"\"\"\n",
    "    Attempts to detect a value by progressively expanding the crop region.\n",
    "    Returns the first detected text or None if no detection is made within max_expansion.\n",
    "    \"\"\"\n",
    "    expansion = 0\n",
    "    new_det = []\n",
    "    while not new_det and expansion <= max_expansion:\n",
    "        crop_region = calculate_value_crop(label_bbox, screenshot, offset=initial_offset, expansion=expansion)\n",
    "        cropped = screenshot[crop_region[1]:crop_region[1]+crop_region[3],\n",
    "                             crop_region[0]:crop_region[0]+crop_region[2]]\n",
    "        new_det = extract_fundamentals_text(ocr, cropped)\n",
    "        if new_det:\n",
    "            break\n",
    "        expansion += 1\n",
    "    return new_det[0]['text'] if new_det else None\n",
    "\n",
    "\n",
    "def process_fundamentals(detections, screenshot, ocr):\n",
    "    last_label, last_bbox = None, None\n",
    "    labels, values = [], []\n",
    "    \n",
    "    for det in detections:\n",
    "        text = det['text']\n",
    "        bbox = det['bbox']\n",
    "        if is_numerical(text) or text.isupper():\n",
    "            if last_label is not None:\n",
    "                labels.append(last_label)\n",
    "                values.append(text)\n",
    "                last_label = None  # reset after pairing\n",
    "        else:\n",
    "            if text == 'Equity':\n",
    "                continue\n",
    "            elif last_label:\n",
    "                labels.append(last_label)\n",
    "                new_value = detect_value_with_expansion(ocr, screenshot, last_bbox, initial_offset=5)\n",
    "                values.append(new_value)\n",
    "            last_label = text\n",
    "            last_bbox = bbox\n",
    "    \n",
    "    # Handle a leftover label.\n",
    "    if last_label and last_label != 'Equity':\n",
    "        labels.append(last_label)\n",
    "        new_value = detect_value_with_expansion(ocr, screenshot, last_bbox, initial_offset=5)\n",
    "        values.append(new_value)\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "\n",
    "def extract_fundamentals(ocr, prev_list=None):\n",
    "    try:\n",
    "        top_screenshot_boundary = pyautogui.locateOnScreen(\"assets/fundamentals/metric.png\", confidence=0.9)\n",
    "    except pyautogui.ImageNotFoundException:\n",
    "        top_screenshot_boundary = pyautogui.locateOnScreen(\"assets/fundamentals/top_border.png\", confidence=0.9)\n",
    "    left = top_screenshot_boundary.left\n",
    "    top = top_screenshot_boundary.top + top_screenshot_boundary.height\n",
    "    width = 550\n",
    "    height = BOTTOM - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "    \n",
    "    text_list = extract_fundamentals_text(ocr, screenshot)\n",
    "    if text_list:\n",
    "        if len(text_list) <= 15:\n",
    "            return process_fundamentals(text_list, screenshot, ocr)\n",
    "        else:\n",
    "            current_list = process_fundamentals(text_list, screenshot, ocr)\n",
    "            if prev_list:\n",
    "                if set(current_list) == set(prev_list):\n",
    "                    return current_list\n",
    "                return list(set(current_list + prev_list))\n",
    "            scroll(-999)\n",
    "            return extract_fundamentals(ocr, current_list)\n",
    "    raise Exception('extract_fundamentals() error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning functions\n",
    "def clean_labels(label, col):\n",
    "    if col == 'industries':\n",
    "        if isinstance(label, str):\n",
    "            if label.endswith('-Discontinuedeff09/19/2020'):\n",
    "                return label.split('-')[0]\n",
    "        return label\n",
    "    \n",
    "    elif col == 'holding_types':\n",
    "        if isinstance(label, str):\n",
    "            if label.startswith('■'):\n",
    "                return label[1:]\n",
    "            elif label.startswith('1'):\n",
    "                return label[1:]\n",
    "        return label\n",
    "    elif col == 'debtors':\n",
    "        if isinstance(label, str):\n",
    "            if ('（') in label:\n",
    "                return label.replace('（', '(')\n",
    "        return label\n",
    "    elif col == 'fundamentals':\n",
    "        if isinstance(label, str):\n",
    "            if label == 'LTDebt/ShareholdersEquity':\n",
    "                return 'LTDebt/Shareholders'\n",
    "        return label\n",
    "    return label\n",
    "    \n",
    "def correct_digit(value_str):\n",
    "    try:\n",
    "        digit = re.sub(r'[^\\d.-]', '', value_str).strip()\n",
    "        return float(digit)\n",
    "    except Exception:\n",
    "        return value_str\n",
    "\n",
    "def clean_values(value_str, col):\n",
    "    # print(value_str)\n",
    "    if col == 'profile':\n",
    "        return value_str\n",
    "    if isinstance(value_str, str):\n",
    "        if value_str.endswith('%'):\n",
    "            return correct_digit(value_str.replace('%',''))/100\n",
    "        try:\n",
    "            return correct_digit(value_str)\n",
    "        except Exception:\n",
    "            return value_str\n",
    "    return value_str\n",
    "\n",
    "def clean_df(df):\n",
    "    for col in df.columns:\n",
    "        # print(col)\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "        df[col] = df[col].apply(lambda x: [(clean_labels(item[0], col), item[1]) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: [(item[0], clean_values(item[1], col)) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: sorted(x, key=lambda item: item[0] if isinstance(item, tuple) and item[0] else '') if isinstance(x, list) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep functions\n",
    "def evaluate_literal(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "    \n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "    return df\n",
    "\n",
    "def save(df):\n",
    "    final_df = df[df.apply(is_row_valid, axis=1)]\n",
    "    final_df = clean_df(final_df)\n",
    "    try:\n",
    "        temp_df = load('data/contract_elaborated.csv')\n",
    "        temp_df = clean_df(temp_df)\n",
    "        final_df = pd.concat([final_df, temp_df]).drop_duplicates(subset=['symbol', 'exact_search', 'search_exchange', 'search_symbol'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Filter out the duplicates with 'exact_search' is False\n",
    "    duplicates_df = final_df[final_df.duplicated(subset='symbol', keep=False)]\n",
    "    final_df = final_df.drop(duplicates_df[duplicates_df['exact_search'] == False].index)\n",
    "\n",
    "    final_df.to_csv('data/contract_elaborated.csv', index=False)\n",
    "\n",
    "def is_numerical(val):\n",
    "    try:\n",
    "        val = str(val).replace('%', '')\n",
    "        float(val)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_valid_tuple(tuple, column):\n",
    "    def extract_float(value):\n",
    "        match = re.match(r'[^0-9]*([0-9.,]+)', value)\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))\n",
    "        return None\n",
    "    \n",
    "    label, value = tuple\n",
    "    if not isinstance(label, str): # keep\n",
    "        # if label != None: # Comment out for more rigid filter\n",
    "        return False\n",
    "    if value is None:\n",
    "        return True # Comment out for more rigid filter\n",
    "        return False \n",
    "    if is_numerical(value):\n",
    "        return True\n",
    "    \n",
    "    if column == 'profile':\n",
    "        # if value and label:\n",
    "        return True\n",
    "    if column == 'fundamentals':\n",
    "        if value.isupper():\n",
    "            return True\n",
    "    if column == 'dividends':\n",
    "        if value == 'Unknown':\n",
    "            return True\n",
    "        extract_float_value = extract_float(value)\n",
    "        if extract_float_value is not None:\n",
    "            return True\n",
    "    if column == 'style':\n",
    "        if isinstance(value, bool):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_row_valid(row):\n",
    "    for col in row.index:\n",
    "        if isinstance(row[col], list):\n",
    "            # if col == 'fundamentals':\n",
    "            #     if len(row[col]) not in [4,5,21,22,   23]: #4, 5, 21, 22 are the acceptable num of fund values, 23 is for little bugs\n",
    "            #         print(len(row[col]))\n",
    "            #         return False\n",
    "            for tuple in row[col]:\n",
    "                if not is_valid_tuple(tuple, col):\n",
    "                    print(tuple)\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def has_bad_multiplier(long_name):\n",
    "    cleaned = long_name.replace('-', '').replace('+', '')\n",
    "    for word in cleaned.split():\n",
    "        if re.fullmatch(r'\\d+X', word):\n",
    "            if int(word[:-1]) > 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_remaining():\n",
    "    contract_details = load('data/contract_details.csv')\n",
    "    try:\n",
    "        final_df = load('data/contract_elaborated.csv')\n",
    "        final_df = final_df[final_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "        exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True) | (~final_df['profile'].isna())\n",
    "        # exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True)\n",
    "        symbols_to_exclude = final_df[exclusion_condition]['symbol']\n",
    "        remaining = contract_details[~contract_details['symbol'].isin(symbols_to_exclude)]\n",
    "\n",
    "        # # To debug invalid rows\n",
    "        # remaining = final_df.copy()\n",
    "        # remaining = remaining[~remaining.apply(is_row_valid, axis=1)]\n",
    "    except FileNotFoundError:\n",
    "        remaining = contract_details.copy()\n",
    "        \n",
    "    remaining = remaining[~remaining['longName'].apply(has_bad_multiplier)]\n",
    "    remaining = remaining[['symbol', 'exchange', 'primaryExchange', 'validExchanges', 'currency', 'conId', 'longName', 'stockType', 'isin']]\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(remaining, data_dict_list, wait_time):\n",
    "    global counter\n",
    "    exchange_bug = False\n",
    "    iteration = 0\n",
    "\n",
    "    # for _, row in tqdm(remaining.sort_values(by='conId').iloc[::-1].iterrows(), total=len(remaining)):\n",
    "    # for _, row in tqdm(remaining.sort_values(by='conId').iterrows(),  total=len(remaining)):\n",
    "    # for _, row in tqdm(remaining.iloc[15::-1].iterrows(), total=len(remaining)):\n",
    "    for _, row in tqdm(remaining.iloc[counter:].iterrows(), total=len(remaining)):\n",
    "        ocr = PaddleOCR()\n",
    "        profile, tradable, holding_types, dividends, top10, industries, countries, currencies, debtors, maturity, debt_type, fundamentals, lipper, style= None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                if exchange_bug:\n",
    "                    search_exchange, search_symbol, exchange_bug = search_eft(ocr, row, 1)\n",
    "                else:\n",
    "                    search_exchange, search_symbol, exchange_bug = search_eft(ocr, row, wait_time)\n",
    "                exact_search = True\n",
    "            except Exception as e:\n",
    "                if e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                    raise Exception('manual')\n",
    "                exchange_bug = quick_search_etf(row)\n",
    "                # if exchange_bug:\n",
    "                #     exchange_bug = quick_search_etf(row, len(remaining['longName'].max()))\n",
    "                # else:\n",
    "                #     exchange_bug = quick_search_etf(row, 5)\n",
    "                exact_search, search_symbol = False, None\n",
    "                search_exchange = check_title(ocr, row['symbol'])\n",
    "                if not search_exchange:\n",
    "                    counter += 1\n",
    "                    continue\n",
    "\n",
    "            # Overview\n",
    "            tradable = check_tradable(seconds=wait_time)\n",
    "            style = extract_style()\n",
    "            profile = extract_profile(ocr)\n",
    "            lipper = extract_lipper(ocr)\n",
    "            holding_types = extract_holding_types(ocr)\n",
    "            dividends = extract_dividends(ocr)\n",
    "\n",
    "            # Holdings tab\n",
    "            if select_tab('holdings', wait_time):\n",
    "                top10 = extract_top10(ocr)\n",
    "                industries = extract_industry(ocr)\n",
    "                countries = extract_country(ocr)\n",
    "                currencies = extract_currency(ocr)\n",
    "\n",
    "            # Bond data\n",
    "            try:\n",
    "                debtors = extract_debtors(ocr, 'debtor_quality')\n",
    "                maturity = extract_debtors(ocr, 'maturity')\n",
    "                debt_type = extract_debtors(ocr, 'debt_type')\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Ratios and Fundamentals tab\n",
    "            if select_tab('fundamentals', wait_time):\n",
    "                fundamentals = extract_fundamentals(ocr)\n",
    "\n",
    "        except Exception as e:\n",
    "            if exchange_bug or e.args and len(e.args) > 0 and e.args[0] == 'skip':\n",
    "                pass\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                print(e)\n",
    "                raise Exception('manual')\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "                raise Exception('manual')\n",
    "            else:\n",
    "                # traceback.print_exc()\n",
    "                print(f'\\nmain() {e} - Symbol: {row[\"symbol\"]} - Name: {row[\"longName\"]} - Exchange: {row[\"exchange\"]}\\n')\n",
    "                counter += 1\n",
    "                return\n",
    "\n",
    "        data_dict = {\n",
    "            'date_scraped': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'exchange_bug': exchange_bug,\n",
    "            'exact_search': exact_search,\n",
    "            'search_exchange': search_exchange,\n",
    "            'search_symbol': search_symbol,\n",
    "            'tradable': tradable,\n",
    "            'profile': profile,\n",
    "            'style': style,\n",
    "            'lipper': lipper,\n",
    "            'fundamentals': fundamentals,\n",
    "            'holding_types': holding_types,\n",
    "            'dividends': dividends,\n",
    "            'top10': top10,\n",
    "            'industries': industries,\n",
    "            'countries': countries,\n",
    "            'currencies': currencies,\n",
    "            'debtors': debtors,\n",
    "            'maturity': maturity,\n",
    "            'debt_type': debt_type,\n",
    "        }\n",
    "\n",
    "        row_dict = row.to_dict()\n",
    "        data_dict = {**row_dict, **data_dict}\n",
    "        data_dict_list.append(data_dict)\n",
    "        gc.collect()\n",
    "        if exchange_bug:\n",
    "            raise Exception(f'bug found')\n",
    "        iteration += 1\n",
    "        if iteration > 100:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_broken(date=datetime.now()):\n",
    "    try:\n",
    "        final_df = load('data/contract_elaborated.csv')\n",
    "        final_df = final_df[final_df.apply(is_row_valid, axis=1)]\n",
    "        final_df['date_scraped'] = pd.to_datetime(final_df['date_scraped'])\n",
    "\n",
    "        date_condition = final_df['date_scraped'].dt.date < pd.to_datetime(date).date()\n",
    "        broken = final_df[date_condition]\n",
    "        # nan_condition = (final_df['dividends'].isna()) | (final_df['profile'].isna())\n",
    "        # broken = final_df[date_condition & nan_condition]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise Exception('contract_elaborated.csv is empty file. Run main() instead')\n",
    "        \n",
    "    broken = broken[~broken['longName'].apply(has_bad_multiplier)]\n",
    "    broken = broken#[['symbol', 'exchange', 'primaryExchange', 'validExchanges', 'currency', 'conId', 'longName', 'stockType', 'isin']]\n",
    "    return broken\n",
    "\n",
    "def save_update(data_dict_list):\n",
    "    failed = 0\n",
    "    try:\n",
    "        existing_df = load('data/contract_elaborated.csv')\n",
    "    except FileNotFoundError:\n",
    "        raise Exception('contract_elaborated.csv is empty file. Run main() instead')\n",
    "\n",
    "    for data_dict in data_dict_list:\n",
    "        key_cols = ['symbol', 'exact_search', 'search_exchange', 'search_symbol']\n",
    "        # key_cols = ['symbol', 'exact_search', 'search_symbol', 'isin']\n",
    "\n",
    "        evaluated_dict = {}\n",
    "        for col in key_cols:\n",
    "            evaluated_dict[col] = evaluate_literal(data_dict[col]) if col in data_dict else None\n",
    "\n",
    "        if not existing_df.empty:\n",
    "            mask = (existing_df[key_cols] == pd.Series(evaluated_dict)[key_cols]).all(axis=1)\n",
    "            if mask.any():\n",
    "                idx = existing_df.index[mask][0]\n",
    "                # Update only non-None fields\n",
    "                for col, value in data_dict.items():\n",
    "                    if value is not None:\n",
    "                        existing_df.at[idx, col] = value\n",
    "            else:\n",
    "                print(f'{data_dict['symbol']} failed')\n",
    "                print(f'    {evaluated_dict}')\n",
    "                print(f'    {existing_df[existing_df['symbol']==data_dict['symbol']][['symbol', 'exact_search', 'search_exchange', 'search_symbol']]}')\n",
    "                failed +=1\n",
    "        else:\n",
    "            raise Exception('contract_elaborated.csv is empty file. Run main() instead')\n",
    "\n",
    "    # Clean and handle duplicates (similar to save)\n",
    "    final_df = existing_df[existing_df.apply(is_row_valid, axis=1)]\n",
    "    final_df = clean_df(final_df)\n",
    "    # Remove duplicates, keeping rows with exact_search=True when possible\n",
    "    duplicates_df = final_df[final_df.duplicated(subset='symbol', keep=False)]\n",
    "    final_df = final_df.drop(duplicates_df[duplicates_df['exact_search'] == False].index)\n",
    "    \n",
    "    final_df.to_csv('data/contract_elaborated.csv', index=False)\n",
    "    return failed\n",
    "\n",
    "def update(broken, data_dict_list, wait_time, tabs_to_update):\n",
    "    global counter\n",
    "    exchange_bug = False\n",
    "    iteration = 0\n",
    "\n",
    "    for _, row in tqdm(broken.iloc[counter:].iterrows(), total=len(broken)):\n",
    "        ocr = PaddleOCR()\n",
    "        search_exchange, search_symbol, exact_search, tradable, style, profile, lipper, holding_types, dividends, top10, industries, countries, currencies, debtors, maturity, debt_type, fundamentals = [None] * 17\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                if exchange_bug:\n",
    "                    search_exchange, search_symbol, exchange_bug = search_eft(ocr, row, 1)\n",
    "                else:\n",
    "                    search_exchange, search_symbol, exchange_bug = search_eft(ocr, row, wait_time)\n",
    "                exact_search = True\n",
    "            except Exception as e:\n",
    "                if e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                    raise Exception('manual')\n",
    "                exchange_bug = quick_search_etf(row)\n",
    "                exact_search, search_symbol = False, None\n",
    "                search_exchange = check_title(ocr, row['symbol'])\n",
    "                if not search_exchange:\n",
    "                    counter += 1\n",
    "                    continue\n",
    "\n",
    "            # Selective scraping based on tabs_to_update\n",
    "            if 'overview' in tabs_to_update:\n",
    "                tradable = check_tradable(seconds=wait_time)\n",
    "                style = extract_style()\n",
    "                profile = extract_profile(ocr)\n",
    "                lipper = extract_lipper(ocr)\n",
    "                holding_types = extract_holding_types(ocr)\n",
    "                dividends = extract_dividends(ocr)\n",
    "\n",
    "            if 'holdings' in tabs_to_update:\n",
    "                if select_tab('holdings', wait_time):\n",
    "                    top10 = extract_top10(ocr)\n",
    "                    industries = extract_industry(ocr)\n",
    "                    countries = extract_country(ocr)\n",
    "                    currencies = extract_currency(ocr)\n",
    "                try:\n",
    "                    debtors = extract_debtors(ocr, 'debtor_quality')\n",
    "                    maturity = extract_debtors(ocr, 'maturity')\n",
    "                    debt_type = extract_debtors(ocr, 'debt_type')\n",
    "                except Exception:\n",
    "                    pass  # Remain None if extraction fails\n",
    "\n",
    "            if 'fundamentals' in tabs_to_update:\n",
    "                if select_tab('fundamentals', wait_time):\n",
    "                    fundamentals = extract_fundamentals(ocr)\n",
    "\n",
    "        except Exception as e:\n",
    "            if exchange_bug or (e.args and len(e.args) > 0 and e.args[0] == 'skip'):\n",
    "                pass\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                print(e)\n",
    "                raise Exception('manual')\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "                raise Exception('manual')\n",
    "            else:\n",
    "                # traceback.print_exc()\n",
    "                print(f'\\nupdate() {e} - Symbol: {row[\"symbol\"]} - Name: {row[\"longName\"]} - Exchange: {row[\"exchange\"]}\\n')\n",
    "                counter += 1\n",
    "                return\n",
    "\n",
    "        # Create data dictionary\n",
    "        data_dict = {\n",
    "            'date_scraped': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'exchange_bug': exchange_bug,\n",
    "            'exact_search': exact_search,\n",
    "            'search_exchange': search_exchange,\n",
    "            'search_symbol': search_symbol,\n",
    "            'tradable': tradable,\n",
    "            'style': style,\n",
    "            'profile': profile,\n",
    "            'lipper': lipper,\n",
    "            'holding_types': holding_types,\n",
    "            'dividends': dividends,\n",
    "            'top10': top10,\n",
    "            'industries': industries,\n",
    "            'countries': countries,\n",
    "            'currencies': currencies,\n",
    "            'debtors': debtors,\n",
    "            'maturity': maturity,\n",
    "            'debt_type': debt_type,\n",
    "            'fundamentals': fundamentals,\n",
    "        }\n",
    "        row_dict = row.to_dict()\n",
    "        data_dict = {**row_dict, **data_dict}\n",
    "        data_dict_list.append(data_dict)\n",
    "        gc.collect()\n",
    "        if exchange_bug:\n",
    "            raise Exception('bug found')\n",
    "        iteration += 1\n",
    "        if iteration > 100:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Run main\n",
    "---\n",
    "1. Start Trader Workstation\n",
    "2. Set custom font size to 18 in settings\n",
    "3. Restart TW and open fundamental explorer\n",
    "4. Type in and load any instrument\n",
    "5. Minimize and maximize fundamental explorer window to fill the window width.\n",
    "6. Set keyboard input to qwerty US\n",
    "7. Now you can run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data_dict_list' in globals() and data_dict_list:\n",
    "    df = pd.DataFrame(data_dict_list)\n",
    "    # df.at[1, 'dividends'] = [('Div.YieldTTM', 0.0322), ('DividendTTM', 'HKD0.77'), ('PayoutRatio', 0.2791)]\n",
    "    backup = pd.concat([backup, df]).drop_duplicates(subset=['symbol', 'exact_search', 'search_exchange', 'search_symbol'])\n",
    "    save(backup)\n",
    "backup = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "counter = 1\n",
    "while True:\n",
    "    try:\n",
    "        switch_to_app()\n",
    "        BOTTOM = 1070\n",
    "        positions = {\n",
    "            'file': (82, 44),\n",
    "            'file_fund_option': (143, 120),\n",
    "            'maximize': (51, 40),\n",
    "            'search_box': (100, 45),\n",
    "        }\n",
    "        data_dict_list = []\n",
    "        remaining = get_remaining()\n",
    "        main(remaining, data_dict_list, wait_time=6)\n",
    "        df = pd.DataFrame(data_dict_list)\n",
    "        save(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(counter)\n",
    "        # traceback.print_exc()\n",
    "        if data_dict_list:\n",
    "            df = pd.DataFrame(data_dict_list)\n",
    "            backup = pd.concat([backup, df]).drop_duplicates(subset=['symbol', 'exact_search', 'search_exchange', 'search_symbol'])\n",
    "            save(df)\n",
    "        else:\n",
    "            raise Exception('none found')\n",
    "\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'bug found':\n",
    "            print('bug found')\n",
    "            break\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "            print('manual')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Run update\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ALL DATES 1 DAY BACK\n",
    "# contracts_df = load('data/contract_elaborated.csv')\n",
    "# contracts_df['date_scraped'] = pd.to_datetime(contracts_df['date_scraped']) - pd.Timedelta(days=1)\n",
    "# contracts_df.to_csv('data/contract_elaborated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE\n",
    "counter = 350\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        switch_to_app()\n",
    "        BOTTOM = 1070\n",
    "        positions = {\n",
    "            'file': (82, 44),\n",
    "            'file_fund_option': (143, 120),\n",
    "            'maximize': (51, 40),\n",
    "            'search_box': (100, 45),\n",
    "        }\n",
    "        data_dict_list = []\n",
    "        tabs_to_update = ['overview']#, 'holdings', 'fundamentals'\n",
    "        date = pd.to_datetime('2025-03-07')\n",
    "        broken = get_broken(date)\n",
    "        # broken = get_broken()\n",
    "        update(broken, data_dict_list, wait_time=6, tabs_to_update=tabs_to_update)\n",
    "        counter += save_update(data_dict_list)\n",
    "        \n",
    "    except Exception as e:\n",
    "        counter += save_update(data_dict_list)\n",
    "        print(counter)\n",
    "\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'bug found':\n",
    "            print('bug found')\n",
    "            break\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'contract_elaborated.csv is empty file. Run main() instead':\n",
    "            print('contract_elaborated.csv is empty file. Run main() instead')\n",
    "            break\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "            print('manual')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clean manually\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['top10', 'industries', 'countries', 'currencies', 'debtors', 'maturity', 'debt_type']\n",
    "mask = contracts_df['holding_types'].notna() & contracts_df[columns_to_check].isna().all(axis=1)\n",
    "bad_symbols = contracts_df[mask]['symbol'].to_list()\n",
    "bad_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts_df = load('data/contract_elaborated.csv')\n",
    "contracts_df = clean_df(contracts_df)\n",
    "contracts_df = contracts_df[contracts_df.apply(is_row_valid, axis=1)]\n",
    "# contracts_df = contracts_df[contracts_df['exact_search'] == False]\n",
    "# contracts_df = contracts_df[~contracts_df['symbol'].isin(bad_symbols)]\n",
    "# contracts_df = contracts_df[contracts_df['exchange_bug'] == True]\n",
    "contracts_df#.to_csv('data/contract_elaborated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CHECK ALL rows scraped during and before march 05\n",
    "\n",
    "- lipper\n",
    "- dividends\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual checks\n",
    "contracts_df = load('data/contract_elaborated.csv')\n",
    "contracts_df = clean_df(contracts_df)\n",
    "contracts_df = contracts_df[contracts_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "# 'profile', 'style', 'lipper', 'fundamentals', 'holding_types', 'dividends', 'top10', 'industries', 'countries', 'currencies', 'debtors', 'maturity', 'debt_type'\n",
    "column = 'currencies'\n",
    "\n",
    "filtered_column = contracts_df[column].dropna().tolist()\n",
    "\n",
    "# Extract elem[1] from all lists\n",
    "all_second_elements = []\n",
    "for fundamentals_list in filtered_column:\n",
    "    if isinstance(fundamentals_list, list):\n",
    "        for elem in fundamentals_list:\n",
    "            if isinstance(elem, tuple) and len(elem) > 1:\n",
    "                all_second_elements.append(elem[0]) # Set 1 to see unique values, 0 to see unique labels\n",
    "\n",
    "# Get unique values\n",
    "unique_labels = list(set(all_second_elements))\n",
    "# unique_labels = list(set([elem if isinstance(elem, str) else 'NUMBSR' for elem in unique_labels]))\n",
    "# unique_labels = list(set([elem if isinstance(elem, float) else np.nan for elem in unique_labels]))\n",
    "unique_labels.sort()\n",
    "unique_labels, len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similarity\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "strings = [s.strip('...') for s in unique_labels]\n",
    "strings = [re.sub(r'\\d+', '', s) for s in strings]\n",
    "\n",
    "unknown_terms = ['other', 'unknown', 'undefined', 'unidentified', 'other', 'noHolding', 'NotClassified', 'NotAvailable', '<NoCurrency>']\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "unknown_embeddings = model.encode(unknown_terms)\n",
    "\n",
    "classifications = []\n",
    "embeddings = model.encode(strings)\n",
    "similarities = cosine_similarity(embeddings, unknown_embeddings)\n",
    "max_similarities = np.max(similarities, axis=1)\n",
    "for s, max_sim in zip(strings, max_similarities):\n",
    "    if max_sim > 0.4:  # Threshold of 0.8\n",
    "        classifications.append((s, \"unknown\"))\n",
    "    else:\n",
    "        classifications.append((s, \"other\"))\n",
    "\n",
    "potential_unknowns = [s for s, cls in classifications if cls == \"unknown\"]\n",
    "potential_unknowns, len(potential_unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['AccountsPayable',\n",
    "'AccountsReceivable',\n",
    "'AccountsReceivable&Pay',\n",
    "'AdministrationFees',\n",
    "'CustodyFees',\n",
    "'ManagementFees',\n",
    "'OtherAssets',\n",
    "'OtherAssetsandLiabilities',\n",
    "'OtherAssetslessLiabilities',\n",
    "'OtherFees',\n",
    "'OtherLiabilities',\n",
    "'Tax',\n",
    "'Tax--ManagementFees']\n",
    "test = list(set(test))\n",
    "test.sort()\n",
    "test\n",
    "test = list(set(test))\n",
    "test.sort()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = ['Equity', 'SalestoTotalAssetsLTDebt/Shareholders'] # Change manually\n",
    "\n",
    "splice = contracts_df[contracts_df[column].apply(lambda x: isinstance(x, list) and any(elem[0] in bad_labels or elem[0] == None or elem[0] == '' for elem in x))]\n",
    "symbols = splice['symbol'].to_list()\n",
    "bad_symbols += symbols\n",
    "# bad_symbols = symbols\n",
    "bad_symbols =  list(set(bad_symbols))\n",
    "display(splice[['symbol','exchange', 'primaryExchange', 'search_exchange', column]])\n",
    "print(len(bad_symbols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bad_symbols))\n",
    "\n",
    "contracts_df['lengths'] = contracts_df['fundamentals'].apply(lambda x: len(x) if isinstance(x, list) else np.nan)\n",
    "splice = contracts_df[(contracts_df['lengths'] != 5) & (contracts_df['lengths'] != 22)][['symbol', 'exchange', 'primaryExchange', 'lengths']]\n",
    "splice = splice[~splice['lengths'].isna()]\n",
    "symbols = splice['symbol'].to_list()\n",
    "bad_symbols += symbols\n",
    "bad_symbols =  list(set(bad_symbols))\n",
    "\n",
    "print(len(bad_symbols))\n",
    "## 22 or 5, sometimes 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
