{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ib_async import *\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape product list\n",
    "if input('Scrape new products? (y/n)').lower().strip() == 'y':\n",
    "    driver = webdriver.Chrome()\n",
    "    url = 'https://www.interactivebrokers.ie/en/trading/products-exchanges.php'\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    input('Navigate to PRODUCT TAB, and pick desired filters')\n",
    "\n",
    "    # Start scraping tables\n",
    "    def extract_table_data():\n",
    "        table = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'tableContacts')))\n",
    "        headers = [header.text for header in table.find_elements(By.TAG_NAME, 'th')]\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "        data = []\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "            data.append([cell.text for cell in cells])\n",
    "        return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "\n",
    "    master_df = extract_table_data()\n",
    "    total_pages = int(driver.find_element(By.CSS_SELECTOR, '.form-pagination span').text.strip())\n",
    "    for i in range(1, total_pages):\n",
    "        forward_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.btn.btn-xs.btn-default.btn-forward')))\n",
    "        driver.execute_script(\"arguments[0].click();\", forward_button)\n",
    "\n",
    "        page_df = extract_table_data()\n",
    "        master_df = pd.concat([master_df, page_df], ignore_index=True)\n",
    "\n",
    "    products_found_text = driver.find_element(By.CSS_SELECTOR, '.text-start.fs-9.text-primary.d-inline strong').text\n",
    "    products_found = int(products_found_text.replace(',', ''))\n",
    "    driver.quit()\n",
    "\n",
    "    if len(master_df) == products_found:\n",
    "        try:\n",
    "            existing_df = pd.read_csv('data/ib_products.csv')\n",
    "            master_df = pd.concat([existing_df, master_df]).drop_duplicates()\n",
    "            print('Updating previous scrape')\n",
    "        except FileNotFoundError:\n",
    "            print('Previous scrape file not found. Saving this scrape')\n",
    "            pass\n",
    "        master_df.to_csv('data/ib_products.csv', index=False)\n",
    "    else:\n",
    "        print(f\"Number listed in site({products_found}) doesn't match number extracted({len(master_df)}). Nothing will be saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing symbols\n",
    "df = pd.read_csv('data/ib_products.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df = df.rename(columns={'exchange  *primary exchange': 'exchange', 'ibkr symbol': 'ibkr_symbol'})\n",
    "df['exchange'] = df['exchange'].str.replace('*', '')\n",
    "\n",
    "# Get contract details for each ETF\n",
    "try:\n",
    "    details_dfs = []\n",
    "    merge_cols = ['symbol', 'currency', 'exchange']\n",
    "    contracts_df = pd.read_csv('data/contract_details.csv')\n",
    "    merged_df = df.merge(contracts_df[merge_cols], on=merge_cols, how='left', indicator=True)\n",
    "    unchecked_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "except Exception:\n",
    "    contracts_df = pd.DataFrame()\n",
    "    unchecked_df = df[merge_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ibkr\n",
    "if not 'ib' in globals():\n",
    "    util.startLoop()\n",
    "\n",
    "    ib = IB()\n",
    "    ib.connect('127.0.0.1', 7497, clientId=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(unchecked_df.iterrows(), total=len(unchecked_df)):\n",
    "    symbol = row['symbol']\n",
    "    exchange = row['exchange']\n",
    "    currency = row['currency']\n",
    "\n",
    "    details_list = ib.reqContractDetails(Stock(symbol, exchange, currency))\n",
    "    if not details_list:\n",
    "        details_list = ib.reqContractDetails(Stock(symbol, 'SMART', currency))\n",
    "\n",
    "    if details_list:\n",
    "        details_df = util.df(details_list)\n",
    "        contract_dict = vars(details_df['contract'].iloc[0])\n",
    "        contract_dict = {k: v for k, v in contract_dict.items() if v}\n",
    "        contract_df = pd.DataFrame([contract_dict])\n",
    "\n",
    "        details_df = pd.concat([contract_df, details_df], axis=1)\n",
    "        details_df.drop('contract', axis=1, inplace=True)\n",
    "\n",
    "        details_dfs.append(details_df)\n",
    "\n",
    "if details_dfs:\n",
    "    details_df = pd.concat(details_dfs, ignore_index=True)\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "    details_df = details_df.replace('', np.nan)\n",
    "    details_df = details_df.dropna(axis=1, how='all')\n",
    "    details_df = details_df.dropna(axis=0)\n",
    "\n",
    "    for index, row in details_df.iterrows():\n",
    "        for tag_value in row['secIdList']:\n",
    "            tag = tag_value.tag.lower().strip()\n",
    "            details_df.at[index, tag] = tag_value.value\n",
    "    details_df.drop(columns=['secIdList'], inplace=True)\n",
    "\n",
    "    single_value_columns = [col for col in details_df.columns if details_df[col].nunique() == 1]\n",
    "    details_df = details_df.drop(columns=single_value_columns, errors='ignore')\n",
    "\n",
    "    cols_to_drop = ['suggestedSizeIncrement', 'sizeIncrement', 'minSize', 'marketRuleIds', 'aggGroup', 'liquidHours', 'tradingHours', 'timeZoneId', 'priceMagnifier', 'orderTypes', 'minTick', 'localSymbol', 'tradingClass', 'marketName']\n",
    "    details_df = details_df.drop(columns=cols_to_drop).dropna(axis=0)\n",
    "    contracts_df = pd.concat([contracts_df, details_df]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Sort by currency and exchanges\n",
    "    currency_trade_volume_order = [\"EUR\", \"USD\", \"JPY\", \"GBP\", \"CNY\", \"AUD\", \"CAD\", \"CHF\", \"SGD\", \"HKD\", \"SEK\", \"NOK\", \"MXN\", \"INR\", \"RUB\", \"PLN\", \"TWD\", \"ZAR\", \"DKK\", \"ILS\", \"MYR\", \"SAR\", \"HUF\", ]\n",
    "    contracts_df['currency_ordered'] = pd.Categorical(contracts_df['currency'], categories=currency_trade_volume_order, ordered=True)\n",
    "    eur_exchanges = contracts_df[contracts_df['currency'] == 'EUR'].primaryExchange.unique()\n",
    "    contracts_df = (contracts_df\n",
    "                    .assign(exchange_is_european=contracts_df['exchange'].isin(eur_exchanges))\n",
    "                    .assign(primary_is_european=contracts_df['primaryExchange'].isin(eur_exchanges))\n",
    "                    .sort_values(by=['currency_ordered', 'exchange_is_european', 'primary_is_european'], ascending=[True, False, False])\n",
    "                    .drop(columns=['currency_ordered', 'exchange_is_european', 'primary_is_european'])\n",
    "                    )\n",
    "    \n",
    "    contracts_df.to_csv('data/contract_details.csv', index=False)\n",
    "else:\n",
    "    print('None found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by currency and exchanges\n",
    "currency_trade_volume_order = [\"EUR\", \"USD\", \"JPY\", \"GBP\", \"CNY\", \"AUD\", \"CAD\", \"CHF\", \"SGD\", \"HKD\", \"SEK\", \"NOK\", \"MXN\", \"INR\", \"RUB\", \"PLN\", \"TWD\", \"ZAR\", \"DKK\", \"ILS\", \"MYR\", \"SAR\", \"HUF\"]\n",
    "contracts_df['currency_ordered'] = pd.Categorical(contracts_df['currency'], categories=currency_trade_volume_order, ordered=True)\n",
    "eur_exchanges = contracts_df[contracts_df['currency'] == 'EUR'].primaryExchange.unique()\n",
    "contracts_df = (contracts_df\n",
    "                .assign(exchange_is_european=contracts_df['exchange'].isin(eur_exchanges))\n",
    "                .assign(primary_is_european=contracts_df['primaryExchange'].isin(eur_exchanges))\n",
    "                .sort_values(by=['currency_ordered', 'exchange_is_european', 'primary_is_european'], ascending=[True, False, False])\n",
    "                .drop(columns=['currency_ordered', 'exchange_is_european', 'primary_is_european'])\n",
    "                )\n",
    "\n",
    "contracts_df.to_csv('data/contract_details.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
