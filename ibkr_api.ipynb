{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ib_async import *\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Scrape available IBKR ETFs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = 'https://www.interactivebrokers.ie/en/trading/products-exchanges.php#/'\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'modal-content')))\n",
    "    reject_button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.ID, 'gdpr-reject-all')))\n",
    "    reject_button.click()\n",
    "except Exception:\n",
    "    print('No GDPR modal found')\n",
    "\n",
    "sleep(2) # because the client refreshes the page after rejecting the cookies\n",
    "dropdown_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.accordion_btn[tabindex=\"1\"]')))\n",
    "dropdown_button.click()\n",
    "\n",
    "etf_checkbox = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'ETF')]/preceding-sibling::input[@type='checkbox']\")))\n",
    "etf_checkbox.click()\n",
    "\n",
    "apply_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \".btn.btn-sm.btn-primary\")))\n",
    "driver.execute_script(\"arguments[0].click();\", apply_button)\n",
    "\n",
    "# rows_per_page_select = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '.form-select')))\n",
    "# select = Select(rows_per_page_select)\n",
    "# select.select_by_value('500')\n",
    "\n",
    "\n",
    "# Start scraping tables\n",
    "def extract_table_data():\n",
    "    table = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, 'tableContacts')))\n",
    "    headers = [header.text for header in table.find_elements(By.TAG_NAME, 'th')]\n",
    "    rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "    data = []\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "        data.append([cell.text for cell in cells])\n",
    "    return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "\n",
    "master_df = extract_table_data()\n",
    "total_pages = int(driver.find_element(By.CSS_SELECTOR, '.form-pagination span').text.strip())\n",
    "for i in range(1, total_pages):\n",
    "    forward_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.btn.btn-xs.btn-default.btn-forward')))\n",
    "    driver.execute_script(\"arguments[0].click();\", forward_button)\n",
    "\n",
    "    page_df = extract_table_data()\n",
    "    master_df = pd.concat([master_df, page_df], ignore_index=True)\n",
    "\n",
    "products_found_text = driver.find_element(By.CSS_SELECTOR, '.text-start.fs-9.text-primary.d-inline strong').text\n",
    "products_found = int(products_found_text.replace(',', ''))\n",
    "driver.quit()\n",
    "\n",
    "if len(master_df) == products_found:\n",
    "    try:\n",
    "        existing_df = pd.read_csv('data/ib_products.csv')\n",
    "        master_df = pd.concat([existing_df, master_df]).drop_duplicates()\n",
    "        print('Updating previous scrape')\n",
    "    except FileNotFoundError:\n",
    "        print('Previous scrape file not found. Saving this scrape')\n",
    "        pass\n",
    "    master_df.to_csv('data/ib_products.csv', index=False)\n",
    "else:\n",
    "    print(f\"Number listed in site({products_found}) doesn't match number extracted({len(master_df)}). Nothing will be saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load ETFs and start up IBKR API\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ETF csvs\n",
    "df = pd.read_csv('data/ib_products.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df = df.drop('product', axis=1)\n",
    "df = df.rename(columns={'exchange  *primary exchange': 'exchange', 'ibkr symbol': 'ibkr_symbol'})\n",
    "\n",
    "regions = df['region'].unique()\n",
    "region_dict = {}\n",
    "for region in regions:\n",
    "    if region == 'XX':\n",
    "        region_dict[region] = 'XX - Other'\n",
    "    else:\n",
    "        country = pycountry.countries.get(alpha_2=region)\n",
    "        if country:\n",
    "            region_dict[region] = f\"{region} - {country.name}\"\n",
    "        else:\n",
    "            region_dict[region] = f\"{region} - Unknown\"\n",
    "\n",
    "df['region'] = df['region'].map(region_dict)\n",
    "\n",
    "# Filter to EUR etfs\n",
    "df['exchange'] = df['exchange'].str.replace('*', '')\n",
    "# df = df[df['currency'] == 'EUR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Contract Details\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ibkr\n",
    "util.startLoop()\n",
    "\n",
    "ib = IB()\n",
    "ib.connect('127.0.0.1', 7497, clientId=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contract details for each ETF\n",
    "try:\n",
    "    contracts_df = pd.read_csv('data/contract_details.csv') \n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if 'contracts_df' in locals() and isinstance(contracts_df, pd.DataFrame):\n",
    "    merged_df = df.merge(contracts_df[['symbol', 'exchange']], on=['symbol', 'exchange'], how='left', indicator=True)\n",
    "    unchecked_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "    details_dfs = []\n",
    "else:\n",
    "    contract_df = pd.DataFrame()\n",
    "    unchecked_df = df.copy()\n",
    "    details_dfs = []\n",
    "\n",
    "for _, row in tqdm(unchecked_df.iterrows(), total=len(unchecked_df)):\n",
    "    symbol = row['symbol']\n",
    "    exchange = row['exchange']\n",
    "    currency = row['currency']\n",
    "\n",
    "    details_list = ib.reqContractDetails(Stock(symbol, exchange, currency))\n",
    "    if not details_list:\n",
    "        # print(f'{row['symbol']}')\n",
    "        details_list = ib.reqContractDetails(Stock(symbol, 'SMART', currency))\n",
    "\n",
    "    if details_list:\n",
    "        details_df = util.df(details_list)\n",
    "        contract_dict = vars(details_df['contract'].iloc[0])\n",
    "        contract_dict = {k: v for k, v in contract_dict.items() if v}\n",
    "        contract_df = pd.DataFrame([contract_dict])\n",
    "\n",
    "        details_df = pd.concat([contract_df, details_df], axis=1)\n",
    "        # details_df.replace('', np.nan, inplace=True)\n",
    "        # details_df.drop('contract', axis=1, inplace=True)\n",
    "\n",
    "        details_dfs.append(details_df)\n",
    "\n",
    "if details_dfs:\n",
    "    details_dfs = pd.concat(details_dfs, ignore_index=True)\n",
    "    details_dfs.replace('', np.nan, inplace=True)\n",
    "\n",
    "    for index, row in details_dfs.iterrows():\n",
    "        for tag_value in row['secIdList']:\n",
    "            tag = tag_value.tag.lower().strip()\n",
    "            details_dfs.at[index, tag] = tag_value.value\n",
    "    details_dfs.drop(columns=['secIdList'], inplace=True)\n",
    "\n",
    "    details_dfs = details_dfs.loc[:, details_dfs.isna().mean() != 1]\n",
    "    contracts_df = pd.concat([contracts_df, details_dfs]).drop_duplicates().reset_index(drop=True)\n",
    "    contracts_df.to_csv('data/contract_details.csv', index=False)\n",
    "    display(details_dfs)\n",
    "else:\n",
    "    print('None found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
