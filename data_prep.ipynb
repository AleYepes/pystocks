{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import pycountry\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep functions\n",
    "def evaluate_literal(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "    \n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "    return df\n",
    "\n",
    "def save(df):\n",
    "    final_df = df[df.apply(is_row_valid, axis=1)]\n",
    "    final_df = clean_df(final_df)\n",
    "    try:\n",
    "        temp_df = load('data/contract_elaborated.csv')\n",
    "        temp_df = clean_df(temp_df)\n",
    "        final_df = pd.concat([final_df, temp_df]).drop_duplicates(subset=['symbol', 'exact_search', 'search_exchange', 'search_symbol'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Filter out the duplicates with 'exact_search' is False\n",
    "    duplicates_df = final_df[final_df.duplicated(subset='symbol', keep=False)]\n",
    "    final_df = final_df.drop(duplicates_df[duplicates_df['exact_search'] == False].index)\n",
    "\n",
    "    final_df.to_csv('data/contract_elaborated.csv', index=False)\n",
    "\n",
    "def is_numerical(val):\n",
    "    try:\n",
    "        val = str(val).replace('%', '')\n",
    "        float(val)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_valid_tuple(tuple, column):\n",
    "    def extract_float(value):\n",
    "        match = re.match(r'[^0-9]*([0-9.,]+)', value)\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))\n",
    "        return None\n",
    "    \n",
    "    label, value = tuple\n",
    "    if not isinstance(label, str): # keep\n",
    "        # if label != None: # Comment out for more rigid filter\n",
    "        return False\n",
    "    if value is None:\n",
    "        return True # Comment out for more rigid filter\n",
    "        return False \n",
    "    if is_numerical(value):\n",
    "        return True\n",
    "    \n",
    "    if column == 'profile':\n",
    "        # if value and label:\n",
    "        return True\n",
    "    if column == 'fundamentals':\n",
    "        if value.isupper():\n",
    "            return True\n",
    "    if column == 'dividends':\n",
    "        if value == 'Unknown':\n",
    "            return True\n",
    "        extract_float_value = extract_float(value)\n",
    "        if extract_float_value is not None:\n",
    "            return True\n",
    "    if column == 'style':\n",
    "        if isinstance(value, bool):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_row_valid(row):\n",
    "    for col in row.index:\n",
    "        if isinstance(row[col], list):\n",
    "            # if col == 'fundamentals':\n",
    "            #     if len(row[col]) not in [4,5,21,22,   23]: #4, 5, 21, 22 are the acceptable num of fund values, 23 is for little bugs\n",
    "            #         print(len(row[col]))\n",
    "            #         return False\n",
    "            for tuple in row[col]:\n",
    "                if not is_valid_tuple(tuple, col):\n",
    "                    print(tuple)\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def has_bad_multiplier(long_name):\n",
    "    cleaned = long_name.replace('-', '').replace('+', '')\n",
    "    for word in cleaned.split():\n",
    "        if re.fullmatch(r'\\d+X', word):\n",
    "            if int(word[:-1]) > 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_remaining():\n",
    "    contract_details = load('data/contract_details.csv')\n",
    "    try:\n",
    "        final_df = load('data/contract_elaborated.csv')\n",
    "        final_df = final_df[final_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "        exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True) | (~final_df['profile'].isna())\n",
    "        # exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True)\n",
    "        symbols_to_exclude = final_df[exclusion_condition]['symbol']\n",
    "        remaining = contract_details[~contract_details['symbol'].isin(symbols_to_exclude)]\n",
    "\n",
    "        # # To debug invalid rows\n",
    "        # remaining = final_df.copy()\n",
    "        # remaining = remaining[~remaining.apply(is_row_valid, axis=1)]\n",
    "    except FileNotFoundError:\n",
    "        remaining = contract_details.copy()\n",
    "        \n",
    "    remaining = remaining[~remaining['longName'].apply(has_bad_multiplier)]\n",
    "    remaining = remaining[['symbol', 'exchange', 'primaryExchange', 'validExchanges', 'currency', 'conId', 'longName', 'stockType', 'isin']]\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep functions 2\n",
    "def evaluate_literal(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "    \n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "    return df\n",
    "\n",
    "def save(df):\n",
    "    final_df = df[df.apply(is_row_valid, axis=1)]\n",
    "    final_df = clean_df(final_df)\n",
    "    try:\n",
    "        temp_df = load('data/contract_elaborated.csv')\n",
    "        temp_df = clean_df(temp_df)\n",
    "        final_df = pd.concat([final_df, temp_df]).drop_duplicates(subset=['symbol', 'exact_search', 'search_exchange', 'search_symbol'])\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Filter out the duplicates with 'exact_search' is False\n",
    "    duplicates_df = final_df[final_df.duplicated(subset='symbol', keep=False)]\n",
    "    final_df = final_df.drop(duplicates_df[duplicates_df['exact_search'] == False].index)\n",
    "\n",
    "    final_df.to_csv('data/contract_elaborated.csv', index=False)\n",
    "\n",
    "def is_numerical(val):\n",
    "    try:\n",
    "        val = str(val).replace('%', '')\n",
    "        float(val)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def is_valid_tuple(tuple, column):\n",
    "    def extract_float(value):\n",
    "        match = re.match(r'[^0-9]*([0-9.,]+)', value)\n",
    "        if match:\n",
    "            return float(match.group(1).replace(',', ''))\n",
    "        return None\n",
    "    \n",
    "    label, value = tuple\n",
    "    if not isinstance(label, str): # keep\n",
    "        # if label != None: # Comment out for more rigid filter\n",
    "        return False\n",
    "    if value is None:\n",
    "        return True # Comment out for more rigid filter\n",
    "        return False \n",
    "    if is_numerical(value):\n",
    "        return True\n",
    "    \n",
    "    if column == 'profile':\n",
    "        # if value and label:\n",
    "        return True\n",
    "    if column == 'fundamentals':\n",
    "        if value.isupper():\n",
    "            return True\n",
    "    if column == 'dividends':\n",
    "        if value == 'Unknown':\n",
    "            return True\n",
    "        extract_float_value = extract_float(value)\n",
    "        if extract_float_value is not None:\n",
    "            return True\n",
    "    if column == 'style':\n",
    "        if isinstance(value, bool):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_row_valid(row):\n",
    "    for col in row.index:\n",
    "        if isinstance(row[col], list):\n",
    "            # if col == 'fundamentals':\n",
    "            #     if len(row[col]) not in [4,5,21,22,   23]: #4, 5, 21, 22 are the acceptable num of fund values, 23 is for little bugs\n",
    "            #         print(len(row[col]))\n",
    "            #         return False\n",
    "            for tuple in row[col]:\n",
    "                if not is_valid_tuple(tuple, col):\n",
    "                    print(tuple)\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "def has_bad_multiplier(long_name):\n",
    "    cleaned = long_name.replace('-', '').replace('+', '')\n",
    "    for word in cleaned.split():\n",
    "        if re.fullmatch(r'\\d+X', word):\n",
    "            if int(word[:-1]) > 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_remaining():\n",
    "    contract_details = load('data/contract_details.csv')\n",
    "    try:\n",
    "        final_df = load('data/contract_elaborated.csv')\n",
    "        final_df = final_df[final_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "        exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True) | (~final_df['profile'].isna())\n",
    "        # exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['exact_search'] == True)\n",
    "        symbols_to_exclude = final_df[exclusion_condition]['symbol']\n",
    "        remaining = contract_details[~contract_details['symbol'].isin(symbols_to_exclude)]\n",
    "\n",
    "        # # To debug invalid rows\n",
    "        # remaining = final_df.copy()\n",
    "        # remaining = remaining[~remaining.apply(is_row_valid, axis=1)]\n",
    "    except FileNotFoundError:\n",
    "        remaining = contract_details.copy()\n",
    "        \n",
    "    remaining = remaining[~remaining['longName'].apply(has_bad_multiplier)]\n",
    "    remaining = remaining[['symbol', 'exchange', 'primaryExchange', 'validExchanges', 'currency', 'conId', 'longName', 'stockType', 'isin']]\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning functions\n",
    "def clean_labels(label, col):\n",
    "    if col == 'industries':\n",
    "        if isinstance(label, str):\n",
    "            if label.endswith('-Discontinuedeff09/19/2020'):\n",
    "                return label.split('-')[0]\n",
    "        return label\n",
    "    \n",
    "    elif col == 'holding_types':\n",
    "        if isinstance(label, str):\n",
    "            if label.startswith('■'):\n",
    "                return label[1:]\n",
    "            elif label.startswith('1'):\n",
    "                return label[1:]\n",
    "        return label\n",
    "    elif col == 'debtors':\n",
    "        if isinstance(label, str):\n",
    "            if ('（') in label:\n",
    "                return label.replace('（', '(')\n",
    "        return label\n",
    "    elif col == 'fundamentals':\n",
    "        if isinstance(label, str):\n",
    "            if label == 'LTDebt/ShareholdersEquity':\n",
    "                return 'LTDebt/Shareholders'\n",
    "        return label\n",
    "    return label\n",
    "    \n",
    "def correct_digit(value_str):\n",
    "    try:\n",
    "        digit = re.sub(r'[^\\d.-]', '', value_str).strip()\n",
    "        return float(digit)\n",
    "    except Exception:\n",
    "        return value_str\n",
    "\n",
    "def clean_values(value_str, col):\n",
    "    # print(value_str)\n",
    "    if col == 'profile':\n",
    "        return value_str\n",
    "    if isinstance(value_str, str):\n",
    "        if value_str.endswith('%'):\n",
    "            return correct_digit(value_str.replace('%',''))/100\n",
    "        try:\n",
    "            return correct_digit(value_str)\n",
    "        except Exception:\n",
    "            return value_str\n",
    "    return value_str\n",
    "\n",
    "def clean_df(df):\n",
    "    for col in df.columns:\n",
    "        # print(col)\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "        df[col] = df[col].apply(lambda x: [(clean_labels(item[0], col), item[1]) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: [(item[0], clean_values(item[1], col)) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: sorted(x, key=lambda item: item[0] if isinstance(item, tuple) and item[0] else '') if isinstance(x, list) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning functions 2\n",
    "def clean_labels(label, col):\n",
    "    if col == 'industries':\n",
    "        if isinstance(label, str):\n",
    "            if label.endswith('-Discontinuedeff09/19/2020'):\n",
    "                return label.split('-')[0]\n",
    "        return label\n",
    "    \n",
    "    elif col == 'holding_types':\n",
    "        if isinstance(label, str):\n",
    "            if label.startswith('■'):\n",
    "                return label[1:]\n",
    "            elif label.startswith('1'):\n",
    "                return label[1:]\n",
    "        return label\n",
    "    elif col == 'debtors':\n",
    "        if isinstance(label, str):\n",
    "            if ('（') in label:\n",
    "                return label.replace('（', '(')\n",
    "        return label\n",
    "    elif col == 'fundamentals':\n",
    "        if isinstance(label, str):\n",
    "            if label == 'LTDebt/ShareholdersEquity':\n",
    "                return 'LTDebt/Shareholders'\n",
    "        return label\n",
    "    return label\n",
    "    \n",
    "def correct_digit(value_str):\n",
    "    try:\n",
    "        digit = re.sub(r'[^\\d.-]', '', value_str).strip()\n",
    "        return float(digit)\n",
    "    except Exception:\n",
    "        return value_str\n",
    "\n",
    "def clean_values(value_str, col):\n",
    "    # print(value_str)\n",
    "    if col == 'profile':\n",
    "        return value_str\n",
    "    if isinstance(value_str, str):\n",
    "        if value_str.endswith('%'):\n",
    "            return correct_digit(value_str.replace('%',''))/100\n",
    "        try:\n",
    "            return correct_digit(value_str)\n",
    "        except Exception:\n",
    "            return value_str\n",
    "    return value_str\n",
    "\n",
    "def clean_df(df):\n",
    "    for col in df.columns:\n",
    "        # print(col)\n",
    "        df[col] = df[col].apply(evaluate_literal)\n",
    "        df[col] = df[col].apply(lambda x: [(clean_labels(item[0], col), item[1]) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: [(item[0], clean_values(item[1], col)) if isinstance(item, tuple) and len(item) == 2 else item for item in x] if isinstance(x, list) else x)\n",
    "        df[col] = df[col].apply(lambda x: sorted(x, key=lambda item: item[0] if isinstance(item, tuple) and item[0] else '') if isinstance(x, list) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode columns\n",
    "contracts_df = load('data/contract_elaborated.csv')\n",
    "contracts_df = clean_df(contracts_df)\n",
    "contracts_df = contracts_df[contracts_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "empty_subcategories = {\n",
    "'holding_types': ['holding_types_Other'],\n",
    "'countries': ['countries_Unidentified'], \n",
    "'currencies': ['currencies_<NoCurrency>'],\n",
    "'industries': ['industries_NonClassifiedEquity', 'industries_NotClassified-NonEquity'],\n",
    "'top10': ['AccountsPayable','AccountsReceivable','AccountsReceivable&Pay','AdministrationFees','CustodyFees','ManagementFees','OtherAssets','OtherAssetsandLiabilities','OtherAssetslessLiabilities','OtherFees','OtherLiabilities','Tax','Tax--ManagementFees'],\n",
    "'debtors': ['OTHER',],\n",
    "'debt_type': ['debt_type_%QualityNotAvailable', 'debt_type_%QualityNotRated'],\n",
    "'maturity': ['maturity_%MaturityOther'],\n",
    "}\n",
    "\n",
    "original_columns = contracts_df.columns\n",
    "columns_to_explode = ['profile', 'style', 'fundamentals', 'holding_types', 'countries', 'currencies', 'industries', 'top10']#,'debtors', 'maturity', 'debt_type']#, 'lipper', 'dividends']\n",
    "percentage_columns = [col for col in ['holding_types', 'countries', 'currencies', 'industries', 'top10', 'debtors', 'maturity', 'debt_type'] if col in columns_to_explode]\n",
    "for col in columns_to_explode:\n",
    "    contracts_df[col] = contracts_df[col].fillna('[]')\n",
    "    contracts_df[col] = contracts_df[col].apply(evaluate_literal)\n",
    "\n",
    "    # Explode and create pivot_df\n",
    "    contracts_df = contracts_df.explode(col)\n",
    "    contracts_df[col] = contracts_df[col].apply(lambda x: (None, None) if pd.isna(x) else x)\n",
    "    contracts_df[['label', 'value']] = pd.DataFrame(contracts_df[col].tolist(), index=contracts_df.index)\n",
    "    pivot_df = contracts_df.pivot_table(index=contracts_df.index, columns='label', values='value', aggfunc='first')\n",
    "    pivot_df.rename(columns={label: f'{col}_{label}' for label in pivot_df.columns}, inplace=True)\n",
    "\n",
    "    # Correct pivot_vf values\n",
    "    if col in percentage_columns:\n",
    "        print(col)\n",
    "        pivot_df = pivot_df.fillna(0.0).clip(lower=0)\n",
    "        columns_to_drop = [f'{col}_{label}' for label in empty_subcategories[col]]\n",
    "        pivot_cols = [pivot_col for pivot_col in pivot_df.columns if pivot_col not in columns_to_drop]\n",
    "\n",
    "        # Clean up errors\n",
    "        if col:\n",
    "            pivot_cols_sum = pivot_df[pivot_cols].sum(axis=1)\n",
    "            mask = pivot_cols_sum > 1\n",
    "            pivot_df.loc[mask, pivot_cols] = pivot_df.loc[mask, pivot_cols].div(pivot_cols_sum[mask], axis=0)\n",
    "\n",
    "        pivot_df = pivot_df.drop(columns=columns_to_drop, axis=1, errors='ignore')\n",
    "        pivot_df[f'{col}_variety'] = pivot_df[pivot_cols].pow(2).sum(axis=1)\n",
    "        pivot_df[f'{col}_variety'] = pivot_df[f'{col}_variety'].astype(float).replace(0.0, np.nan)\n",
    "\n",
    "        if col == 'top10':\n",
    "            print(f'{col}_variety' in pivot_df.columns.to_list())\n",
    "            columns_to_drop = [column for column in pivot_df.columns if column != f'{col}_variety']\n",
    "            print(f'{col}_variety' in columns_to_drop)\n",
    "            pivot_df = pivot_df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "    contracts_df = contracts_df.drop(columns=[col, 'label', 'value'], axis=1).drop_duplicates(subset='symbol')\n",
    "    contracts_df = pd.concat([contracts_df, pivot_df], axis=1)\n",
    "\n",
    "contracts_df = contracts_df[~contracts_df['profile_TotalNetAssets'].isna()]\n",
    "# for col in percentage_columns:\n",
    "#     full_columns = [full_column for full_column in contracts_df.columns if full_column.startswith(col)]\n",
    "#     contracts_df[full_columns] = contracts_df[full_columns].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety = [column for column in contracts_df.columns if column.endswith('_variety')]\n",
    "\n",
    "# # Check if variety columns are greater than 1\n",
    "# condition = contracts_df[variety].gt(1).any(axis=1)\n",
    "# contracts_df[condition]#[variety]\n",
    "\n",
    "contracts_df[[column for column in contracts_df.columns if column.startswith('industries')]]\n",
    "contracts_df[variety]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Variety factors\n",
    "approaches 1 => little variety\n",
    "approaches 0 => a lot of variety\n",
    "sum of country**2\n",
    "sum of currency**2\n",
    "sum of industry**2\n",
    "sum of top10**2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ETF duplicates\n",
    "basic_classification = [col for col in original_columns if col not in columns_to_explode]\n",
    "remaining_columns = [col for col in contracts_df.columns if col not in basic_classification]\n",
    "og_len = len(contracts_df)\n",
    "contracts_df = (\n",
    "    contracts_df\n",
    "    .assign(is_EUR=contracts_df['currency'] == 'EUR')  # Add column: True if currency is 'EUR'\n",
    "    .sort_values(by='is_EUR', ascending=False)         # Sort so True comes before False\n",
    "    .drop_duplicates(subset=remaining_columns, keep='first')  # Keep first row (prefers 'EUR')\n",
    "    .drop(columns=['is_EUR'])                          # Remove temporary column\n",
    ")\n",
    "og_len - len(contracts_df)\n",
    "contracts_df = contracts_df.dropna(subset='symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct total net assets\n",
    "symbol_mapping = {\n",
    "    '$': 'USD',    # Default to USD\n",
    "    '￥': 'JPY',    # Japanese Yen\n",
    "    'Rs': 'INR',\n",
    "    'CNH': 'CNY',\n",
    "    # '¥': 'JPY',    # Alternative Yen symbol\n",
    "    # '€': 'EUR',    # Euro\n",
    "    # '£': 'GBP',    # British Pound\n",
    "    # 'A$': 'AUD',   # Australian Dollar\n",
    "    # 'C$': 'CAD',   # Canadian Dollar\n",
    "    # 'HK$': 'HKD',  # Hong Kong Dollar\n",
    "}\n",
    "\n",
    "def standardize_currency(currency):\n",
    "    if pd.isna(currency):\n",
    "        return np.nan\n",
    "    if currency in symbol_mapping:\n",
    "        return symbol_mapping[currency]\n",
    "    if currency == '':\n",
    "        return ''\n",
    "    try:\n",
    "        if pycountry.currencies.get(alpha_3=currency):\n",
    "            return currency\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    return currency\n",
    "\n",
    "def clean_total_net_assets(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan, np.nan\n",
    "    value = re.sub(r'\\basof\\b.*', '', value, flags=re.IGNORECASE).strip()\n",
    "    match = re.match(r'([^0-9\\s]+)?\\s*([0-9.,]+)\\s*([kKmMbB]?)', value)\n",
    "    if not match:\n",
    "        return np.nan, np.nan\n",
    "    currency, num_str, unit = match.groups()\n",
    "    currency = currency if currency else ''\n",
    "    num = float(num_str.replace(',', ''))\n",
    "    unit = unit.lower() if unit else ''\n",
    "    if unit == 'k':\n",
    "        num *= 10**3\n",
    "    elif unit == 'm':\n",
    "        num *= 10**6\n",
    "    elif unit == 'b':\n",
    "        num *= 10**9\n",
    "    elif unit == 't':\n",
    "        num *= 10**12\n",
    "    return num, currency\n",
    "\n",
    "def get_exchange_rates(currencies, to_currency='USD'):\n",
    "    rates = {}\n",
    "    valid_currencies = []\n",
    "    for c in currencies:\n",
    "        if pd.notna(c) and pycountry.currencies.get(alpha_3=c) is not None:\n",
    "            valid_currencies.append(c)\n",
    "    if not valid_currencies:\n",
    "        return rates\n",
    "    try:\n",
    "        url = f\"https://open.er-api.com/v6/latest/{to_currency}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if 'rates' in data:\n",
    "            for currency in valid_currencies:\n",
    "                if currency == 'USD':\n",
    "                    rates[currency] = 1.0\n",
    "                elif currency in data['rates']:\n",
    "                    rates[currency] = 1 / data['rates'][currency] if data['rates'][currency] != 0 else np.nan\n",
    "            print(f\"Fetched rates: {rates}\")\n",
    "            return rates\n",
    "        else:\n",
    "            print(f\"Error fetching rates: {data.get('error', 'Unknown error')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exchange rate fetch failed: {e}\")\n",
    "    return rates\n",
    "\n",
    "def convert_to_usd(row, rates):\n",
    "    if pd.isna(row['profile_cap']) or pd.isna(row['profile_cap_currency']):\n",
    "        return np.nan\n",
    "    currency = row['profile_cap_currency']\n",
    "    if currency in rates:\n",
    "        return row['profile_cap'] * rates[currency]\n",
    "    print(f\"No rate available for {currency}\")\n",
    "    return np.nan\n",
    "\n",
    "contracts_df[['profile_cap', 'profile_cap_currency']] = contracts_df['profile_TotalNetAssets'].apply(lambda x: pd.Series(clean_total_net_assets(x)))\n",
    "contracts_df['profile_cap_currency'] = contracts_df['profile_cap_currency'].apply(standardize_currency)\n",
    "contracts_df['profile_cap_currency'] = np.where(contracts_df['profile_cap_currency'] == '', contracts_df['currency'], contracts_df['profile_cap_currency'])\n",
    "contracts_df['profile_cap_currency'] = contracts_df['profile_cap_currency'].apply(lambda x: x if (pd.isna(x) or pycountry.currencies.get(alpha_3=x) or x == '') else np.nan)\n",
    "\n",
    "exchange_rates = get_exchange_rates(contracts_df['profile_cap_currency'].unique())\n",
    "contracts_df['profile_cap_usd'] = contracts_df.apply(lambda row: convert_to_usd(row, exchange_rates),axis=1)\n",
    "contracts_df.loc[contracts_df['stockType'] == 'ETC', 'industries_BasicMaterials'] = 1.0\n",
    "\n",
    "# contracts_df[contracts_df['profile_cap_usd'].isna()][['currency', 'profile_cap_currency', 'profile_cap', 'profile_cap_usd', 'profile_TotalNetAssets', 'profile_Domicile', 'profile_MarketGeoFocus']]\n",
    "contracts_df.to_csv('data/fundamentals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to numerical columns\n",
    "basic_classification = [col for col in original_columns if col not in columns_to_explode]\n",
    "bond_fundamentals = ['fundamentals_AverageQuality', 'fundamentals_NominalMaturity', 'fundamentals_EffectiveMaturity', 'fundamentals_AverageCoupon', 'fundamentals_YieldtoMaturity']\n",
    "profile_classification = ['profile_Domicile', 'profile_MarketGeoFocus', 'profile_BenchmarkIndex', 'profile_FundCategory', 'profile_TotalExpenseRatio', 'profile_TotalNetAssets', 'profile_cap', 'profile_cap_currency', 'profile_MarketCapFocus']\n",
    "\n",
    "classification_columns = basic_classification + bond_fundamentals + profile_classification\n",
    "data_cols = contracts_df.columns[~contracts_df.columns.isin(classification_columns)]\n",
    "\n",
    "data = contracts_df[~contracts_df['fundamentals_Price/Book'].isna()].copy()\n",
    "data = data[~data['fundamentals_LTDebt/Shareholders'].isna()]\n",
    "data = data[~data['style_large-core'].isna()]\n",
    "\n",
    "fundamental_columns = [full_column for full_column in contracts_df.columns if full_column.startswith('fundamentals') and full_column not in bond_fundamentals]\n",
    "for col in fundamental_columns + ['profile_cap_usd']:\n",
    "    data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "\n",
    "data[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph correlations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_df = data[data_cols].corr()\n",
    "\n",
    "# drop columns with missing values\n",
    "corr_df = data[data_cols].corr()\n",
    "corr_df.dropna(axis=1, how='all', inplace=True)\n",
    "corr_df.dropna(axis=0, how='all', inplace=True)\n",
    "data_cols = corr_df.columns\n",
    "\n",
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(corr_df, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Factor definition\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Academic factors\n",
    "Market beta\n",
    "SMB\n",
    "HML\n",
    "RMW\n",
    "\n",
    "\n",
    "# Variety factors\n",
    "approaches 1 => little variety\n",
    "approaches 0 => a lot of variety\n",
    "sum of country**2\n",
    "sum of currency**2\n",
    "sum of industry**2\n",
    "sum of top10**2\n",
    "\n",
    "Check if factors are orthogonal\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in style columns\n",
    "fundamental_columns = [full_column for full_column in contracts_df.columns if full_column.startswith('fundamentals') and full_column not in bond_fundamentals]\n",
    "\n",
    "value_columns = ['fundamentals_Price/Book',  'fundamentals_Price/Cash', 'fundamentals_Price/Earnings', 'fundamentals_Price/Sales']#, 'fundamentals_LTDebt/Shareholders', 'fundamentals_TotalDebt/TotalCapital', 'fundamentals_TotalDebt/TotalEquity']#,  'fundamentals_TotalAssets/TotalEquity']\n",
    "growth_columns = ['fundamentals_EPSGrowth-1yr', 'fundamentals_EPS_growth_3yr', 'fundamentals_EPS_growth_5yr']#, 'fundamentals_ReturnonAssets', 'fundamentals_SalestoTotalAssets']\n",
    "output_columns = [full_column for full_column in contracts_df.columns if full_column.startswith('style')]\n",
    "\n",
    "'''\n",
    "growth score = 2 * [ N_P/B + N_P/E + N_P/Cash + N_P/Sales + N_EPS_growth_1yr + N_EPS_growth_3yr + N_EPS_growth_5yr + \n",
    "              N_ReturnonAssets1Yr + N_ReturnonAssets3Yr + N_ReturnonCapital + N_ReturnonCapital3Yr + \n",
    "              N_ReturnonEquity1Yr + N_ReturnonEquity3Yr + N_ReturnonInvestment1Yr + N_ReturnonInvestment3Yr + \n",
    "              N_SalestoTotalAssets + N_EBITtoInterest + N_RelativeStrength + \n",
    "              (1 - N_LTDebt/ShareholdersEquity) + (1 - N_TotalAssets/TotalEquity) + \n",
    "              (1 - N_TotalDebt/TotalCapital) + (1 - N_TotalDebt/TotalEquity) ] / 22 - 1\n",
    "\n",
    "Extreme Growth: If all growth indicators ≈ 1 and value indicators ≈ 0, then S = [18*1 + 4*1]/22 = 1, score = 2*1 - 1 = 1.\n",
    "Extreme Value: If all growth indicators ≈ 0 and value indicators ≈ 1, then S = [18*0 + 4*0]/22 = 0, score = 2*0 - 1 = -1.\n",
    "Neutral: If all ≈ 0.5, then S = [18*0.5 + 4*0.5]/22 = 0.5, score = 2*0.5 - 1 = 0.\n",
    "\n",
    "\n",
    "Step 4: Proposed Refined Model\n",
    "Balancing your suggestions with practicality and Morningstar’s framework, I recommend:\n",
    "Select Key Metrics: Use only the most relevant IBKR metrics.\n",
    "Equal Weighting Within Categories: Follow Morningstar’s approach for simplicity and grounding.\n",
    "Score Calculation: Compute a value-growth spectrum from -1 to 1.\n",
    "Refined Model\n",
    "Value Score = mean((1 - N_P/B) + (1 - N_P/Sales) + (1 - N_P/Cash) + (1 - N_P/E)) # Possibly add: LTDebt/ShareholdersEquity, TotalDebt/Equity\n",
    "Growth Score = mean(N_EPS_growth_1yr + N_EPS_growth_3yr + N_EPS_growth_5yr) # Possibly add: ReturnonAssets, SalestoTotalAssets\n",
    "\n",
    "Why This Works\n",
    "Relevance: Uses metrics tied to Morningstar’s historical measures and value investing principles.\n",
    "Simplicity: Equal weighting avoids overcomplication while mirroring industry practice.\n",
    "No Additional Standardization: Normalization suffices for comparability.\n",
    "Flexibility: Captures the spectrum effectively with available data.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clustering analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance correlation\n",
    "import dcor\n",
    "\n",
    "training_array = data[data_cols].values # Convert training matrix to numpy array\n",
    "symbol_list = data[data_cols].columns.tolist()\n",
    "num_symbols = len(symbol_list)\n",
    "corr_matrix = np.zeros((num_symbols, num_symbols)) # Pre-allocate numpy array for correlation\n",
    "cov_matrix = np.zeros((num_symbols, num_symbols))  # Pre-allocate numpy array for covariance\n",
    "\n",
    "for i, sym_i in tqdm(enumerate(symbol_list), total=num_symbols, desc=f\"Calculating distance stats sqr\"):\n",
    "    for j, sym_j in enumerate(symbol_list):\n",
    "        if i <= j:  # Compute only for upper triangle (including diagonal)\n",
    "            stats = dcor.distance_stats(training_array[:, i], training_array[:, j])\n",
    "            corr_value = stats.correlation_xy\n",
    "            cov_value = stats.covariance_xy\n",
    "\n",
    "            corr_matrix[i, j] = corr_value\n",
    "            corr_matrix[j, i] = corr_value  # Fill symmetric value\n",
    "\n",
    "            cov_matrix[i, j] = cov_value\n",
    "            cov_matrix[j, i] = cov_value  # Fill symmetric value\n",
    "\n",
    "corr_df = pd.DataFrame(corr_matrix, index=symbol_list, columns=symbol_list) # Convert numpy array back to df for output\n",
    "cov_df = pd.DataFrame(cov_matrix, index=symbol_list, columns=symbol_list)   # Convert numpy array back to df for output\n",
    "\n",
    "\n",
    "# drop columns with missing values\n",
    "corr_df = data[data_cols].corr()#.values\n",
    "corr_df = corr_df.dropna(axis=1, how='all')\n",
    "corr_df.dropna(axis=0, how='all', inplace=True)\n",
    "corr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distance matrix\n",
    "symbol_list = corr_df.columns\n",
    "\n",
    "symbol2index = dict(zip(corr_df.columns, corr_df.index))\n",
    "index2symbol = dict(zip(corr_df.index, corr_df.columns))\n",
    "corr_df.rename(columns=symbol2index, inplace=True)\n",
    "# cov_df.rename(columns=symbol2index, inplace=True)\n",
    "\n",
    "distance_matrix = (1 - corr_df).to_numpy()\n",
    "np.fill_diagonal(distance_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds / cluster_num graphs\n",
    "methods = ['single', 'ward', 'average', 'complete', 'weighted', 'centroid', 'median']\n",
    "methods = ['ward']\n",
    "for method in methods:\n",
    "    linked = sch.linkage(squareform(distance_matrix), method=method)\n",
    "    \n",
    "    num_clusters = range(len(corr_df), 1, -1)\n",
    "    thresholds = linked[:, 2]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(num_clusters, thresholds, marker='o')\n",
    "    plt.title(f\"Threshold/Num ({method})\")\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Threshold (Distance)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Silhouettes and dendrograms\n",
    "def product(row):\n",
    "    product = 1\n",
    "    for value in row.values():\n",
    "        product *= value\n",
    "    return product\n",
    "\n",
    "methods = ['single', 'ward', 'average', 'complete', 'weighted', 'centroid', 'median']\n",
    "methods = ['ward']\n",
    "for method in methods:\n",
    "\n",
    "    ks = []\n",
    "    scores = []\n",
    "    counts = []\n",
    "    for k in range(2, min(len(distance_matrix), 9)):\n",
    "        clusters = AgglomerativeClustering(n_clusters=k, linkage=method).fit_predict(distance_matrix)\n",
    "        score = silhouette_score(distance_matrix, clusters, metric='precomputed')\n",
    "        ks.append(k)\n",
    "        scores.append(score)\n",
    "        unique_clusters, label_counts = np.unique(clusters, return_counts=True)\n",
    "        label_counts_dict = dict(zip(unique_clusters, label_counts))\n",
    "        counts.append(label_counts_dict)\n",
    "\n",
    "    silhouettes = pd.DataFrame({\n",
    "        'k': ks,\n",
    "        'score': scores,\n",
    "        'counts': counts\n",
    "    })\n",
    "    silhouettes['combitions'] = silhouettes['counts'].apply(product)\n",
    "    silhouettes = silhouettes.sort_values(by='score', ascending=False)\n",
    "    best_k = silhouettes.k.iloc[0]\n",
    "    display(silhouettes)\n",
    "\n",
    "    linked = sch.linkage(squareform(distance_matrix), method=method)\n",
    "    plt.figure(figsize=(40, 15))\n",
    "    sch.dendrogram(linked, labels=corr_df.index, leaf_rotation=90)\n",
    "    plt.title(f\"Method {method}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Silhouettes and dendrograms\n",
    "def product(row):\n",
    "    product = 1\n",
    "    for value in row.values():\n",
    "        product *= value\n",
    "    return product\n",
    "\n",
    "methods = ['single', 'ward', 'average', 'complete', 'weighted', 'centroid', 'median']\n",
    "methods = ['ward', 'complete']\n",
    "for method in methods:\n",
    "\n",
    "    ks = []\n",
    "    scores = []\n",
    "    counts = []\n",
    "    for k in range(2, min(len(distance_matrix), 9)):\n",
    "        clusters = AgglomerativeClustering(n_clusters=k, linkage=method).fit_predict(distance_matrix)\n",
    "        score = silhouette_score(distance_matrix, clusters, metric='precomputed')\n",
    "        ks.append(k)\n",
    "        scores.append(score)\n",
    "        unique_clusters, label_counts = np.unique(clusters, return_counts=True)\n",
    "        label_counts_dict = dict(zip(unique_clusters, label_counts))\n",
    "        counts.append(label_counts_dict)\n",
    "\n",
    "    silhouettes = pd.DataFrame({\n",
    "        'k': ks,\n",
    "        'score': scores,\n",
    "        'counts': counts\n",
    "    })\n",
    "    silhouettes['combitions'] = silhouettes['counts'].apply(product)\n",
    "    silhouettes = silhouettes.sort_values(by='score', ascending=False)\n",
    "    best_k = silhouettes.k.iloc[0]\n",
    "    display(silhouettes)\n",
    "\n",
    "    linked = sch.linkage(squareform(distance_matrix), method=method)\n",
    "    plt.figure(figsize=(40, 15))\n",
    "    sch.dendrogram(linked, labels=corr_df.index, leaf_rotation=90)\n",
    "    plt.title(f\"Method {method}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
