{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import traceback\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "from rapidfuzz import fuzz\n",
    "import gc\n",
    "import re\n",
    "from functions import *\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import platform\n",
    "if platform.system() == \"Darwin\":\n",
    "    from AppKit import NSWorkspace, NSApplicationActivateIgnoringOtherApps\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up functions\n",
    "def extract_text(ocr, screenshot):\n",
    "    try:\n",
    "        result = ocr.ocr(screenshot, cls=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        result = [None]\n",
    "\n",
    "    text = []\n",
    "    if result[0]:\n",
    "        for idx in range(len(result)):\n",
    "            res = result[idx]\n",
    "            for line in res:\n",
    "                if line[-1][-1] > 0.85:\n",
    "                    text.append(line[-1][0].replace(' ',''))\n",
    "    # print(result)\n",
    "    return text\n",
    "\n",
    "def scroll(amount, attempts=2):\n",
    "    SCROLL_TOP = 600\n",
    "    SCROLL_BOT = 550\n",
    "    \n",
    "    before = pyautogui.screenshot(region=(0, 25, 1919, 1054))\n",
    "    before = np.array(before)\n",
    "    for _ in range(attempts):\n",
    "        rand_int = random.randint(SCROLL_BOT, SCROLL_TOP)\n",
    "        pyautogui.scroll(amount, rand_int, rand_int)\n",
    "        after = pyautogui.screenshot(region=(0, 25, 1919, 1054))\n",
    "        after = np.array(after)\n",
    "\n",
    "        if not np.array_equal(before, after):\n",
    "            return\n",
    "        \n",
    "    # raise Exception(f'scroll() failed')\n",
    "        \n",
    "def wait(seconds=5, interval=0.5):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "        screenshot = pyautogui.screenshot(region=(10, 280, 440, 200))\n",
    "        screenshot = np.array(screenshot)\n",
    "        screenshot = screenshot[:, :, :3]\n",
    "\n",
    "        if np.any(np.all(screenshot == (247, 247, 247), axis=-1)):\n",
    "            return\n",
    "        sleep(interval)\n",
    "    raise Exception('wait() text never loaded')\n",
    "    \n",
    "def select_tab(name, seconds=5):\n",
    "    try:\n",
    "        scroll(999)\n",
    "        tab = pyautogui.locateCenterOnScreen(f'assets/{name}/tab_label.png', confidence=0.9)\n",
    "        pyautogui.click(tab)\n",
    "        wait(seconds)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    \n",
    "def agree():\n",
    "    while True:\n",
    "        try:\n",
    "            agree = pyautogui.locateOnScreen(\"assets/fund_setup/agree.png\", confidence=0.9)\n",
    "            pyautogui.click(agree)\n",
    "        except Exception:\n",
    "            break\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            tradable_modal = pyautogui.locateOnScreen(\"assets/fund_setup/ok_tradable.png\", confidence=0.9)\n",
    "            left_x = tradable_modal.left + tradable_modal.width // 2\n",
    "            center_y = tradable_modal.top + tradable_modal.height // 2\n",
    "            pyautogui.click(left_x, center_y)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "def clear_modals():\n",
    "    while True:\n",
    "        try:\n",
    "            log_off_timer = pyautogui.locateOnScreen(\"assets/fund_setup/log_off_timer.png\", confidence=0.9)\n",
    "            left_x = log_off_timer.left + 34\n",
    "            center_y = log_off_timer.top + log_off_timer.height // 2\n",
    "            pyautogui.click(left_x, center_y)\n",
    "        except Exception:\n",
    "            break\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            search_error = pyautogui.locateOnScreen(\"assets/fund_setup/search_error.png\", confidence=0.9)\n",
    "            left_x = search_error.left + 25\n",
    "            center_y = search_error.top + search_error.height // 2\n",
    "            pyautogui.click(left_x, center_y)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "def select_exchange():\n",
    "    try:\n",
    "        pyautogui.locateOnScreen(\"assets/fund_setup/contract_selection.png\", confidence=0.9)\n",
    "        pyautogui.press(\"up\")\n",
    "        pyautogui.press(\"enter\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def switch_to_app(app_name='Trader Workstation'):\n",
    "    workspace = NSWorkspace.sharedWorkspace()\n",
    "    apps = workspace.runningApplications()\n",
    "    for app in apps:\n",
    "        if app.localizedName() == app_name:\n",
    "            app.activateWithOptions_(NSApplicationActivateIgnoringOtherApps)\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search functions\n",
    "def exit_search():\n",
    "    pyautogui.press(\"enter\", presses=2, interval=0.3)\n",
    "    # Guarantee that search is selected\n",
    "    try:\n",
    "        dropdown = pyautogui.locateOnScreen(f'assets/fund_setup/dropdown.png', confidence=0.9)\n",
    "        dropdown_position = (dropdown.left + 1, dropdown.top + 1)\n",
    "        pyautogui.click(dropdown_position)\n",
    "    except pyautogui.ImageNotFoundException:\n",
    "        pass\n",
    "\n",
    "    exchange_bug = select_exchange()\n",
    "    agree()\n",
    "    clear_modals()\n",
    "    return exchange_bug\n",
    "\n",
    "def check_search_results(ocr, row, screenshot, screenshot_left, screenshot_top, img_margin, width=800, target_color=[64, 64, 64, 255], background_color=[109, 111, 113, 255]):\n",
    "    matches, adjustable_height, max_adjustable_height, top, row_text_detected_previously = [], 21, 42, img_margin, False\n",
    "\n",
    "    screenshot_array = np.array(screenshot)\n",
    "    mask = np.all(screenshot_array == target_color, axis=-1)\n",
    "    screenshot_array[mask] = background_color\n",
    "    \n",
    "    while True:\n",
    "        # print(top, adjustable_height)\n",
    "        # display(Image.fromarray(screenshot_array[top:top+adjustable_height]))\n",
    "        text_list = extract_text(ocr, screenshot_array[top:top+adjustable_height])\n",
    "        # print(text_list, adjustable_height)\n",
    "        # print(row['symbol'], row['validExchanges'])\n",
    "        \n",
    "        if not text_list:\n",
    "            if not row_text_detected_previously:\n",
    "                break   \n",
    "\n",
    "        if len(text_list) > 1:\n",
    "            search_symbol = text_list[0]\n",
    "            row_symbol = str(row['symbol'])\n",
    "            try:\n",
    "                int(row_symbol)\n",
    "                # confidence = 90\n",
    "                confidence = 85\n",
    "            except Exception:\n",
    "                confidence = 75\n",
    "\n",
    "            if (len(search_symbol) == len(row_symbol)) and fuzz.partial_ratio(search_symbol, row_symbol) >= confidence:\n",
    "                search_exchange = text_list[1:]\n",
    "                search_exchange = [exchange for exchange in search_exchange if '(' in exchange]\n",
    "                position = (screenshot_left + (width / 2), (screenshot_top + top) + adjustable_height / 2)\n",
    "                matches.append((search_exchange, search_symbol, position))\n",
    "            # Move to the next row\n",
    "            top += SEARCH_RESULTS_ROW_HEIGHT + (adjustable_height - SEARCH_RESULTS_ROW_HEIGHT)//2\n",
    "            adjustable_height = SEARCH_RESULTS_ROW_HEIGHT\n",
    "            row_text_detected_previously = False\n",
    "        else:\n",
    "            # Adjust region for better OCR\n",
    "            top -= 1\n",
    "            adjustable_height += 2\n",
    "            row_text_detected_previously = True\n",
    "            if adjustable_height > max_adjustable_height:\n",
    "                top += SEARCH_RESULTS_ROW_HEIGHT + (adjustable_height - SEARCH_RESULTS_ROW_HEIGHT)//2\n",
    "                adjustable_height = SEARCH_RESULTS_ROW_HEIGHT\n",
    "                row_text_detected_previously = False\n",
    "\n",
    "    if matches: \n",
    "        for match in matches: # Solely check exchange matches first\n",
    "            for ex in match[0]:\n",
    "                if fuzz.partial_ratio(row['exchange'], ex) >= 80:\n",
    "                    return ex, match[1], match[2]\n",
    "                \n",
    "        for match in matches: # Then consider primaryExchange matches\n",
    "            for ex in match[0]:\n",
    "                if fuzz.partial_ratio(row['primaryExchange'], ex) >= 80:\n",
    "                    return ex, match[1], match[2]\n",
    "                \n",
    "        valid_exchanges = row['validExchanges'].split(',') if row['validExchanges'] else []\n",
    "        for match in matches: # Finally consider validExchange matches\n",
    "            for ex in match[0]:\n",
    "                for valid_exchange in valid_exchanges:\n",
    "                    if fuzz.partial_ratio(valid_exchange.strip(), ex) >= 80:\n",
    "                        return ex, match[1], match[2]\n",
    "                    \n",
    "        # If no match, return the first ocr result\n",
    "        return np.nan, np.nan, matches[0][2]\n",
    "    return np.nan, np.nan, np.nan\n",
    "        \n",
    "def check_search_table(img_margin, width=800, seconds=8, target_color=[64, 64, 64, 255], background_color=[109, 111, 113, 255]):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "\n",
    "    while datetime.now() - start < timeout:\n",
    "        try:\n",
    "            table_heading = pyautogui.locateOnScreen(f'assets/fund_setup/table_heading.png', confidence=0.9)\n",
    "            sleep(0.1)\n",
    "            heading_screenshot = pyautogui.screenshot(region=(table_heading.left, table_heading.top, table_heading.width, table_heading.height))\n",
    "            heading_screenshot = np.array(heading_screenshot)\n",
    "            if heading_screenshot[0 + 6][-1].tolist() == [121,123,126,255]: # 6px represents the img margin. necessary to identify the correct heading corner \n",
    "                table_heading = pyautogui.locateOnScreen(f'assets/fund_setup/table_heading.png', confidence=0.9)\n",
    "                break\n",
    "        except Exception:\n",
    "            raise Exception('Table heading not found')\n",
    "\n",
    "    table_top = table_heading.top + table_heading.height - img_margin\n",
    "    try:\n",
    "        table_bottom = pyautogui.locateOnScreen(f'assets/fund_setup/search_bottom.png', confidence=0.9)\n",
    "        table_height = table_bottom.top + table_bottom.height - table_top\n",
    "    except pyautogui.ImageNotFoundException:\n",
    "        table_height = 300\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(table_heading.left, table_top, width, table_height))\n",
    "    screenshot_array = np.array(screenshot)\n",
    "    # display(Image.fromarray(screenshot_array))\n",
    "    if screenshot_array[img_margin+2][-1].tolist() == target_color:\n",
    "        return screenshot, table_heading.left, table_top\n",
    "    elif screenshot_array[img_margin+2][-1].tolist() == background_color:\n",
    "        raise Exception('No search results found')\n",
    "    else:\n",
    "        raise Exception('check_search_table() bug')\n",
    "        \n",
    "def search_etf(ocr, row, wait_time=5):\n",
    "    scroll(999)\n",
    "    pyautogui.press(\"esc\")\n",
    "    pyautogui.click(POSITIONS['dead_space'], interval=0.2)\n",
    "    pyautogui.click(POSITIONS['search_box'], interval=0.2)\n",
    "\n",
    "    pyautogui.write(row['longName'])\n",
    "    pyautogui.press(\"enter\")\n",
    "\n",
    "    img_margin = 15 # added img_margin to allow region expansions to retry OCR in check_search_results()\n",
    "    target_color = [64, 64, 64, 255]\n",
    "    background_color = [109, 111, 113, 255]\n",
    "    screenshot, left, top = check_search_table(img_margin, seconds=wait_time, target_color=target_color, background_color=background_color)\n",
    "    \n",
    "    exchange, symbol, row_position = check_search_results(ocr, row, screenshot, left, top, img_margin, target_color=target_color, background_color=background_color) # +1 to center the row text in frame. \n",
    "    if row_position:\n",
    "        pyautogui.click(row_position)\n",
    "        exchange_bug = exit_search()\n",
    "        return exchange, symbol, exchange_bug\n",
    "    else:\n",
    "        clear_modals()\n",
    "        raise Exception('Failed to detect the symbol in the search results')\n",
    "    \n",
    "def quick_search_etf(row, count=None, name=None):\n",
    "    pyautogui.press(\"esc\")\n",
    "    pyautogui.click(POSITIONS['dead_space'], interval=0.2)\n",
    "    pyautogui.click(POSITIONS['search_box'], interval=0.2)\n",
    "    if count:\n",
    "        pyautogui.press(\"delete\", presses=count)\n",
    "        pyautogui.press(\"backspace\", presses=count)\n",
    "    if name:\n",
    "        pyautogui.write(name)\n",
    "    else:\n",
    "        pyautogui.write(str(row['symbol']))\n",
    "\n",
    "    exchange_bug = exit_search()\n",
    "    return exchange_bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "# from typing import List, Tuple\n",
    "\n",
    "# # A data class to hold the properties of the instrument we are searching for.\n",
    "# # This replaces the 'row' dictionary.\n",
    "# @dataclass\n",
    "# class FinancialInstrument:\n",
    "#     symbol: str\n",
    "#     exchange: str\n",
    "#     primary_exchange: str\n",
    "#     valid_exchanges: List[str]\n",
    "\n",
    "# # A data class to hold the details of a match found on the screen.\n",
    "# # This replaces the (search_exchange, search_symbol, position) tuple.\n",
    "# @dataclass\n",
    "# class SearchResult:\n",
    "#     detected_symbol: str\n",
    "#     detected_exchanges: List[str]\n",
    "#     position: Tuple[float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ScreenSearcher:\n",
    "#     ROW_HEIGHT = 21\n",
    "#     MAX_ADJUSTABLE_ROW_HEIGHT = 42\n",
    "#     CONFIDENCE_NUMERIC_SYMBOL = 90\n",
    "#     CONFIDENCE_TEXT_SYMBOL = 75\n",
    "#     CONFIDENCE_EXCHANGE = 80\n",
    "\n",
    "#     def __init__(self, ocr_engine, width=800):\n",
    "#         self.ocr = ocr_engine\n",
    "#         self.screenshot_width = width\n",
    "\n",
    "#     def _preprocess_image(self, screenshot):\n",
    "#         \"\"\"Replaces a specific color in the screenshot to improve OCR accuracy.\"\"\"\n",
    "#         screenshot_array = np.array(screenshot)\n",
    "#         target_color = [64, 64, 64, 255]\n",
    "#         replacement_color = [109, 111, 113, 255]\n",
    "#         mask = np.all(screenshot_array == target_color, axis=-1)\n",
    "#         screenshot_array[mask] = replacement_color\n",
    "#         return screenshot_array\n",
    "\n",
    "#     def _scan_for_potential_matches(self, image_array, instrument: FinancialInstrument, buffer, left, top_coord) -> List[SearchResult]:\n",
    "#         \"\"\"Iteratively scans the image array to find all potential symbol matches.\"\"\"\n",
    "#         matches = []\n",
    "#         top = buffer\n",
    "#         adjustable_height = self.ROW_HEIGHT\n",
    "#         text_detected_in_row = False\n",
    "\n",
    "#         while True:\n",
    "#             # text_list = extract_text(self.ocr, image_array[top:top+adjustable_height]) # Your OCR call\n",
    "#             text_list = [] # Placeholder for your OCR function call\n",
    "\n",
    "#             if not text_list and not text_detected_in_row:\n",
    "#                 break # End of results\n",
    "\n",
    "#             if len(text_list) > 1:\n",
    "#                 search_symbol = text_list[0]\n",
    "#                 is_numeric = str(instrument.symbol).isdigit()\n",
    "#                 confidence = self.CONFIDENCE_NUMERIC_SYMBOL if is_numeric else self.CONFIDENCE_TEXT_SYMBOL\n",
    "                \n",
    "#                 # Check for a symbol match\n",
    "#                 if (len(search_symbol) == len(str(instrument.symbol))) and fuzz.partial_ratio(search_symbol, instrument.symbol) >= confidence:\n",
    "#                     exchanges = [ex for ex in text_list[1:] if '(' in ex]\n",
    "#                     position = (left + (self.screenshot_width / 2), (top_coord + top) + adjustable_height / 2)\n",
    "                    \n",
    "#                     # Using the SearchResult class makes this clear\n",
    "#                     matches.append(SearchResult(\n",
    "#                         detected_symbol=search_symbol,\n",
    "#                         detected_exchanges=exchanges,\n",
    "#                         position=position\n",
    "#                     ))\n",
    "\n",
    "#                 # Move to the next theoretical row\n",
    "#                 top += self.ROW_HEIGHT + (adjustable_height - self.ROW_HEIGHT) // 2\n",
    "#                 adjustable_height = self.ROW_HEIGHT\n",
    "#                 text_detected_in_row = False\n",
    "#             else:\n",
    "#                 # Adjust scan area if text is partial or missing\n",
    "#                 top -= 1\n",
    "#                 adjustable_height += 2\n",
    "#                 text_detected_in_row = True\n",
    "#                 if adjustable_height > self.MAX_ADJUSTABLE_ROW_HEIGHT:\n",
    "#                     top += self.ROW_HEIGHT + (adjustable_height - self.ROW_HEIGHT) // 2\n",
    "#                     adjustable_height = self.ROW_HEIGHT\n",
    "#                     text_detected_in_row = False\n",
    "        \n",
    "#         return matches\n",
    "\n",
    "#     def _verify_best_match(self, matches: List[SearchResult], instrument: FinancialInstrument) -> SearchResult | None:\n",
    "#         \"\"\"Iterates through potential matches to find the best one based on the exchange.\"\"\"\n",
    "#         # 1. Check for the specific exchange\n",
    "#         for match in matches:\n",
    "#             for ex in match.detected_exchanges:\n",
    "#                 if fuzz.partial_ratio(instrument.exchange, ex) >= self.CONFIDENCE_EXCHANGE:\n",
    "#                     return match\n",
    "\n",
    "#         # 2. Check for the primary exchange\n",
    "#         for match in matches:\n",
    "#             for ex in match.detected_exchanges:\n",
    "#                 if fuzz.partial_ratio(instrument.primary_exchange, ex) >= self.CONFIDENCE_EXCHANGE:\n",
    "#                     return match\n",
    "\n",
    "#         # 3. Check against all other valid exchanges\n",
    "#         for match in matches:\n",
    "#             for ex in match.detected_exchanges:\n",
    "#                 for valid_ex in instrument.valid_exchanges:\n",
    "#                     if fuzz.partial_ratio(valid_ex.strip(), ex) >= self.CONFIDENCE_EXCHANGE:\n",
    "#                         return match\n",
    "        \n",
    "#         # 4. Fallback: return the first match if no exchange was verified\n",
    "#         return matches[0] if matches else None\n",
    "\n",
    "#     def find_instrument_on_screen(self, instrument: FinancialInstrument, screenshot, left: int, top: int, buffer: int) -> SearchResult | None:\n",
    "#         \"\"\"\n",
    "#         Main method to orchestrate the search process.\n",
    "#         This is the new entry point, replacing the original function.\n",
    "#         \"\"\"\n",
    "#         preprocessed_image = self._preprocess_image(screenshot)\n",
    "        \n",
    "#         potential_matches = self._scan_for_potential_matches(preprocessed_image, instrument, buffer, left, top)\n",
    "        \n",
    "#         if not potential_matches:\n",
    "#             return None\n",
    "            \n",
    "#         return self._verify_best_match(potential_matches, instrument)\n",
    "\n",
    "\n",
    "# # 1. Initialize the OCR engine and the ScreenSearcher\n",
    "# ocr = PaddleOCR(use_angle_cls=True, lang='en') \n",
    "# searcher = ScreenSearcher(ocr_engine=ocr)\n",
    "\n",
    "# # 2. Create an instance of the instrument you are looking for\n",
    "# row_data = {\n",
    "#     'symbol': 'AAPL', \n",
    "#     'exchange': 'NASDAQ', \n",
    "#     'primaryExchange': 'NASDAQ', \n",
    "#     'validExchanges': 'NASDAQ,NYSE'\n",
    "# }\n",
    "\n",
    "# instrument_to_find = FinancialInstrument(\n",
    "#     symbol=row_data['symbol'],\n",
    "#     exchange=row_data['exchange'],\n",
    "#     primary_exchange=row_data['primaryExchange'],\n",
    "#     valid_exchanges=row_data['validExchanges'].split(',') if row_data['validExchanges'] else []\n",
    "# )\n",
    "\n",
    "# # 3. Call the main method with your data\n",
    "# screenshot_image = Image.open(\"your_screenshot.png\")\n",
    "# screenshot_left, screenshot_top, buffer = 100, 150, 20\n",
    "\n",
    "# best_match = searcher.find_instrument_on_screen(\n",
    "#     instrument=instrument_to_find,\n",
    "#     screenshot=screenshot_image,\n",
    "#     left=screenshot_left,\n",
    "#     top=screenshot_top,\n",
    "#     buffer=buffer\n",
    "# )\n",
    "\n",
    "# # 4. Use the result\n",
    "# if best_match:\n",
    "#     print(f\"Match found for {best_match.detected_symbol}!\")\n",
    "#     print(f\"Detected Exchanges: {best_match.detected_exchanges}\")\n",
    "#     print(f\"Position on screen: {best_match.position}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile functions\n",
    "def process_profile(text_list):\n",
    "    headings = ['TotalExpenseRatio', 'TotalNetAssets', 'BenchmarkIndex', 'Domicile', 'MarketGeoFocus', 'MarketCapFocus', 'FundCategory']\n",
    "    current_label, current_values, labels, values = None, [], [], []\n",
    "    threshold = 80\n",
    "\n",
    "    for item in text_list:\n",
    "        matches = [(heading, fuzz.partial_ratio(item, heading)) for heading in headings]\n",
    "        best_match = max(matches, key=lambda x: x[1])\n",
    "\n",
    "        if best_match[1] >= threshold and (current_label != best_match[0]):\n",
    "            if current_label:\n",
    "                labels.append(current_label)\n",
    "                values.append(' '.join(current_values))\n",
    "                current_values = []\n",
    "            current_label = best_match[0]\n",
    "        else:\n",
    "            current_values.append(item)\n",
    "\n",
    "    if current_label:\n",
    "        labels.append(current_label)\n",
    "        values.append(' '.join(current_values))\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_profile(ocr):\n",
    "    profile = pyautogui.locateOnScreen(\"assets/overview/profile.png\", confidence=0.9)\n",
    "    left = profile.left\n",
    "    top = profile.top + profile.height\n",
    "    lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.9)\n",
    "    width = 600\n",
    "    height = lipper.top - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    scroll(-height/8)\n",
    "    if text_list:\n",
    "        return process_profile(text_list)\n",
    "    else:\n",
    "        raise Exception('skip')\n",
    "    \n",
    "def check_title(ocr, title, seconds=5, interval=1):\n",
    "    start = datetime.now()\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "\n",
    "        # Check for white text\n",
    "        screenshot = pyautogui.screenshot(region=(25, 100, 65, 25))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_color = (247, 247, 247, 255)\n",
    "        if np.any(np.all(screenshot == text_color, axis=-1)):\n",
    "            \n",
    "            # Clear long name\n",
    "            screenshot = pyautogui.screenshot(region=(25, 100, 480, 60))\n",
    "            screenshot_array = np.array(screenshot)\n",
    "\n",
    "            white_pixels = np.all(screenshot_array == [255, 255, 255, 255], axis=-1)\n",
    "            structure = np.ones((19,19), dtype=bool)\n",
    "            surrounding_pixels = binary_dilation(white_pixels, structure=structure) | white_pixels\n",
    "            screenshot_array[surrounding_pixels] = [24,24,24,255]\n",
    "            # display(Image.fromarray(screenshot_array))\n",
    "\n",
    "            text = extract_text(ocr, screenshot_array)\n",
    "            pattern = re.compile(r'[A-Za-z]')\n",
    "\n",
    "            while len(text) > 2 and not pattern.search(text[-1]):\n",
    "                text.pop()\n",
    "\n",
    "            if fuzz.partial_ratio(text[0], title.upper()) >= 85:\n",
    "                return text[0], text[1]\n",
    "            else:\n",
    "                raise Exception(f'Failed to verify that OCR workstation title({text[0]}) is similar enough to product symbol({title.upper()})')\n",
    "\n",
    "def check_tradable(seconds=5, interval=0.5):\n",
    "    timeout = timedelta(seconds=seconds)\n",
    "    start = datetime.now()\n",
    "    sleep(interval)\n",
    "    while datetime.now() - start < timeout:\n",
    "\n",
    "        # Check for white text\n",
    "        screenshot = pyautogui.screenshot(region=(25, 100, 65, 25))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_color = (247, 247, 247, 255)\n",
    "        if np.any(np.all(screenshot == text_color, axis=-1)):\n",
    "\n",
    "            # Check for nt sign\n",
    "            sleep(interval)\n",
    "            screenshot = pyautogui.screenshot(region=(25, 125, 300, 100))\n",
    "            screenshot = np.array(screenshot)\n",
    "            nt_sign_color = (240, 71, 80, 255)\n",
    "            if np.any(np.all(screenshot == nt_sign_color, axis=-1)):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "def process_holding_types(text_list):\n",
    "    # Assumes text is identified from left to right, and top to bottom\n",
    "    for i, element in enumerate(text_list):\n",
    "        if element.strip().isupper():\n",
    "            text_list = text_list[:i]\n",
    "            break\n",
    "\n",
    "    last_label, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            labels.append(last_label)\n",
    "            values.append(item)\n",
    "            last_label = None\n",
    "        else:\n",
    "            if last_label:\n",
    "                labels.append(last_label)\n",
    "                values.append(None)\n",
    "            last_label = item\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_holding_types(ocr):\n",
    "    holdings = pyautogui.locateOnScreen(\"assets/overview/holdings.png\", confidence=0.9)\n",
    "    left = holdings.left\n",
    "    top = holdings.top + holdings.height\n",
    "    dividends = pyautogui.locateOnScreen(\"assets/overview/dividends.png\", confidence=0.9)\n",
    "    width = 600\n",
    "    height = dividends.top - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    # scroll(-height / 8)\n",
    "    if len(text_list) > 1:\n",
    "        return process_holding_types(text_list)\n",
    "    else:\n",
    "        raise Exception('skip')\n",
    "\n",
    "def extract_style():\n",
    "    style = pyautogui.locateOnScreen(\"assets/overview/style_matrix.png\", confidence=0.85)\n",
    "    left = style.left + style.width + 70\n",
    "    width = 280\n",
    "    height = 172\n",
    "    lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.85)\n",
    "    top = lipper.top - height - 113\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "    highlight_colors = [\n",
    "        (29, 51, 88, 255),\n",
    "        (255, 255, 255, 255),\n",
    "        (41, 112, 234, 255)\n",
    "    ]\n",
    "    background_color = (24, 24, 24, 255)\n",
    "\n",
    "    color_matches = np.zeros(screenshot.shape[:-1], dtype=bool)\n",
    "    for color in highlight_colors:\n",
    "        color_matches |= np.all(screenshot == color, axis=-1)\n",
    "\n",
    "    if np.any(color_matches):\n",
    "        styles = []\n",
    "        rows = ['large', 'multi', 'mid', 'small']\n",
    "        columns = ['value', 'core', 'growth']\n",
    "        for i, row in enumerate(rows):\n",
    "            row_step_px = round(height / (len(rows) - 1)) - 1 # First -1 to get the num of internal boundaries == num of areas - 1. Second -1 to avoid index overflow\n",
    "            for j, col in enumerate(columns):\n",
    "                col_step_px = round(width / (len(columns) - 1)) - 1\n",
    "                pixel = screenshot[row_step_px * i][col_step_px * j].tolist()\n",
    "                styles.append((f'{row}-{col}', pixel != list(background_color)))\n",
    "    \n",
    "        return styles\n",
    "\n",
    "def process_lipper(text_index, screenshot, width, height):\n",
    "    bg_color = [24, 24, 24, 255]\n",
    "    missing_color = [0, 0, 0, 255]\n",
    "    row_idx = 16 + round(35 * text_index)\n",
    "    for j in range(5):\n",
    "        col_step_px = round(width/5) - 1\n",
    "        pixel = screenshot[row_idx][col_step_px * (j+1)].tolist()\n",
    "        if pixel == bg_color or pixel == missing_color:\n",
    "            return j + 1\n",
    "\n",
    "def extract_lipper(ocr):\n",
    "    try:\n",
    "        lipper = pyautogui.locateOnScreen(\"assets/overview/lipper.png\", confidence=0.9)\n",
    "        left = lipper.left\n",
    "        top = lipper.top + lipper.height\n",
    "        holdings = pyautogui.locateOnScreen(\"assets/overview/holdings.png\", confidence=0.9)\n",
    "        lipper_width = 300\n",
    "        height = holdings.top - top\n",
    "\n",
    "        screenshot = pyautogui.screenshot(region=(left, top, lipper_width, height))\n",
    "        screenshot = np.array(screenshot)\n",
    "        text_list = extract_text(ocr, screenshot)\n",
    "        if text_list:\n",
    "            width = 285\n",
    "            screenshot = pyautogui.screenshot(region=(left+lipper_width+24, top+12, width, height-12))\n",
    "            screenshot = np.array(screenshot)\n",
    "            \n",
    "            lipper = []\n",
    "            for i, label in enumerate(text_list):\n",
    "                value = process_lipper(i, screenshot, width, 34)\n",
    "                lipper.append((label, value))\n",
    "            scroll(-height/10)\n",
    "            return lipper\n",
    "        scroll(-height/10)\n",
    "    except Exception as e:\n",
    "        raise Exception(f'extract_dividends() {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holding functions\n",
    "def show_more(type=1):\n",
    "    try:\n",
    "        if type != 1:\n",
    "            show_more = pyautogui.locateCenterOnScreen(\"assets/holdings/show_more2.png\", confidence=0.9)\n",
    "        else:\n",
    "            show_more = pyautogui.locateCenterOnScreen(\"assets/holdings/show_more.png\", confidence=0.9)\n",
    "        pyautogui.click(show_more)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def process_top10(text_list):\n",
    "    # Assumes text is identified from left to right, and top to bottom\n",
    "    index, current_labels, labels , values = True, [], [], []\n",
    "\n",
    "    for item in text_list:\n",
    "        if index and len(item) <= 2 and not item.endswith('%'):\n",
    "            index = False \n",
    "        elif is_numerical(item) and item.endswith('%'):\n",
    "            labels.append('-'.join(current_labels))\n",
    "            values.append(item)\n",
    "            current_labels = []\n",
    "            index = True\n",
    "        else:\n",
    "            current_labels.append(item)\n",
    "            index = False \n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_top10(ocr):    \n",
    "    top10 = pyautogui.locateOnScreen(\"assets/holdings/top10.png\", confidence=0.9)\n",
    "    left = top10.left\n",
    "    top = top10.top + top10.height\n",
    "    width = 626\n",
    "    height = 455\n",
    "\n",
    "    return capture_text(ocr, process_top10, left, top, width, height)\n",
    "\n",
    "def process_industry(text_list): # Industry displays labels, value pairs backwards, so ocr reads them backwards\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            if last_value:\n",
    "                labels.append(None)\n",
    "                values.append(last_value)\n",
    "            last_value = item\n",
    "        else:\n",
    "            labels.append(item)\n",
    "            values.append(last_value)\n",
    "            last_value = None\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def process_holding_tables(text_list):\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        value = re.sub(r'[^\\d.%]', '', item)\n",
    "        if is_numerical(value):\n",
    "            labels.append(last_value)\n",
    "            values.append(value)\n",
    "            last_value = None\n",
    "        else:\n",
    "            if last_value:\n",
    "                labels.append(last_value)\n",
    "                values.append(None)\n",
    "            last_value = item\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def process_bonds(text_list):\n",
    "    last_value, labels , values = None, [], []\n",
    "    for item in (text_list):\n",
    "        if is_numerical(item):\n",
    "            labels.append(last_value)\n",
    "            values.append(item)\n",
    "            last_value = None\n",
    "        else:\n",
    "            if last_value:\n",
    "                labels.append(last_value)\n",
    "                values.append(None)\n",
    "            last_value = item\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "def extract_industry(ocr):\n",
    "    show_more()\n",
    "    industry = pyautogui.locateOnScreen(\"assets/holdings/industry.png\", confidence=0.9)\n",
    "    scroll(-(industry.height*3/4))\n",
    "\n",
    "    industry = pyautogui.locateOnScreen(\"assets/holdings/industry.png\", confidence=0.9)\n",
    "    left = industry.left + 40\n",
    "    top = industry.top + industry.height\n",
    "    width = 550\n",
    "    try:\n",
    "        show_less = pyautogui.locateOnScreen(\"assets/holdings/show_less.png\", confidence=0.9)\n",
    "        height = show_less.top - top\n",
    "    except Exception:\n",
    "        height = 450\n",
    "\n",
    "    return capture_text(ocr, process_industry, left, top, width, height)\n",
    "\n",
    "def extract_country(ocr):\n",
    "    country = pyautogui.locateOnScreen(\"assets/holdings/country.png\", confidence=0.9)\n",
    "    scroll(-(country.top/15))\n",
    "    show_more(2)\n",
    "    country = pyautogui.locateOnScreen(\"assets/holdings/country.png\", confidence=0.9)\n",
    "    left = country.left + 50\n",
    "    top = country.top + country.height\n",
    "    width = 460\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    height = currency.top - top\n",
    "\n",
    "    return capture_text(ocr, process_holding_tables, left, top, width, height)\n",
    "\n",
    "def extract_currency(ocr):\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    scroll(-(currency.top/20))\n",
    "    show_more(2)\n",
    "    scroll(-(currency.top/50), 1)\n",
    "    currency = pyautogui.locateOnScreen(\"assets/holdings/currency.png\", confidence=0.9)\n",
    "    left = currency.left + 50\n",
    "    top = currency.top + currency.height\n",
    "    width = 460\n",
    "    try:\n",
    "        debtor = pyautogui.locateOnScreen(\"assets/holdings/debtor_quality.png\", confidence=0.9)\n",
    "        height = debtor.top - top\n",
    "    except Exception:\n",
    "        height = BOTTOM - top\n",
    "\n",
    "    return capture_text(ocr, process_holding_tables, left, top, width, height)\n",
    "\n",
    "# Resize function\n",
    "def capture_text(ocr, function, left, top, width, height):\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "    text_list = extract_text(ocr, screenshot)\n",
    "    if text_list:\n",
    "        try:\n",
    "            return function(text_list)\n",
    "        except:\n",
    "            expand_px = 4\n",
    "            screenshot = screenshot = pyautogui.screenshot(region=(left - expand_px, top - expand_px, width + expand_px*2, height + expand_px*2))\n",
    "            screenshot = np.array(screenshot)\n",
    "            text_list = extract_text(ocr, screenshot)\n",
    "            if text_list:\n",
    "                return function(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bond functions\n",
    "def extract_debtors(ocr, name):\n",
    "    scroll(-499, 1)\n",
    "    debtor = pyautogui.locateOnScreen(f\"assets/holdings/{name}.png\", confidence=0.9)\n",
    "    left = debtor.left\n",
    "    top = debtor.top + debtor.height\n",
    "    width = 405\n",
    "    height = BOTTOM - top\n",
    "\n",
    "    return capture_text(ocr, process_bonds, left, top, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamentals functions\n",
    "def extract_fundamentals_text(ocr, screenshot):\n",
    "    # display(Image.fromarray(screenshot))\n",
    "    try:\n",
    "        results = ocr.ocr(screenshot, cls=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        results = [None]\n",
    "\n",
    "    text_list = []\n",
    "    if results and results[0]:\n",
    "        for res in results:\n",
    "            for line in res:\n",
    "                bbox, (text, conf) = line[0], line[-1]\n",
    "                if conf > 0.85:\n",
    "                    text_list.append({\n",
    "                        'text': text.replace(' ', ''),\n",
    "                        'bbox': bbox,\n",
    "                        'conf': conf\n",
    "                    })\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def calculate_value_crop(label_bbox, screenshot, offset=5, expansion=0):\n",
    "    \"\"\"\n",
    "    Given a label's bounding box, calculates a region where its value should be.\n",
    "    The region is expanded by 'expansion' pixels on all sides.\n",
    "    \"\"\"\n",
    "    # Extract coordinates from label_bbox (assumed to be list of 4 points)\n",
    "    x_coords = [pt[0] for pt in label_bbox]\n",
    "    y_coords = [pt[1] for pt in label_bbox]\n",
    "    label_left, label_top = min(x_coords), min(y_coords)\n",
    "    label_right, label_bottom = max(x_coords), max(y_coords)\n",
    "    \n",
    "    # Initial value region: to the right of the label with a small offset.\n",
    "    initial_value_left = label_right + offset\n",
    "    initial_value_top = label_top\n",
    "    screenshot_width = screenshot.shape[1]\n",
    "    initial_value_width = screenshot_width - initial_value_left\n",
    "    initial_value_height = label_bottom - label_top\n",
    "\n",
    "    # Expand the region by 'expansion' pixels on all sides.\n",
    "    new_x = max(initial_value_left, 0)\n",
    "    new_y = max(initial_value_top - expansion, 0)\n",
    "    new_width = initial_value_width\n",
    "    new_height = initial_value_height + 2 * expansion\n",
    "\n",
    "    # Ensure the region stays within the screenshot boundaries.\n",
    "    if new_x + new_width > screenshot.shape[1]:\n",
    "        new_width = screenshot.shape[1] - new_x\n",
    "    if new_y + new_height > screenshot.shape[0]:\n",
    "        new_height = screenshot.shape[0] - new_y\n",
    "\n",
    "    return (int(new_x), int(new_y), int(new_width), int(new_height))\n",
    "\n",
    "\n",
    "def detect_value_with_expansion(ocr, screenshot, label_bbox, initial_offset=5, max_expansion=49):\n",
    "    \"\"\"\n",
    "    Attempts to detect a value by progressively expanding the crop region.\n",
    "    Returns the first_pass detected text or None if no detection is made within max_expansion.\n",
    "    \"\"\"\n",
    "    expansion = 0\n",
    "    new_det = []\n",
    "    while not new_det and expansion <= max_expansion:\n",
    "        crop_region = calculate_value_crop(label_bbox, screenshot, offset=initial_offset, expansion=expansion)\n",
    "        cropped = screenshot[crop_region[1]:crop_region[1]+crop_region[3],\n",
    "                             crop_region[0]:crop_region[0]+crop_region[2]]\n",
    "        new_det = extract_fundamentals_text(ocr, cropped)\n",
    "        if new_det:\n",
    "            break\n",
    "        expansion += 1\n",
    "    return new_det[0]['text'] if new_det else None\n",
    "\n",
    "\n",
    "def process_fundamentals(detections, screenshot, ocr):\n",
    "    last_label, last_bbox = None, None\n",
    "    labels, values = [], []\n",
    "    \n",
    "    for det in detections:\n",
    "        text = det['text']\n",
    "        bbox = det['bbox']\n",
    "        if is_numerical(text) or text.isupper():\n",
    "            if last_label is not None:\n",
    "                labels.append(last_label)\n",
    "                values.append(text)\n",
    "                last_label = None  # reset after pairing\n",
    "        else:\n",
    "            if text == 'Equity':\n",
    "                continue\n",
    "            elif last_label:\n",
    "                labels.append(last_label)\n",
    "                new_value = detect_value_with_expansion(ocr, screenshot, last_bbox, initial_offset=5)\n",
    "                values.append(new_value)\n",
    "            last_label = text\n",
    "            last_bbox = bbox\n",
    "    \n",
    "    # Handle a leftover label.\n",
    "    if last_label and last_label != 'Equity':\n",
    "        labels.append(last_label)\n",
    "        new_value = detect_value_with_expansion(ocr, screenshot, last_bbox, initial_offset=5)\n",
    "        values.append(new_value)\n",
    "\n",
    "    return list(zip(labels, values))\n",
    "\n",
    "\n",
    "def extract_fundamentals(ocr, prev_list=None):\n",
    "    first_pass = False\n",
    "    try:\n",
    "        top_screenshot_boundary = pyautogui.locateOnScreen(\"assets/fundamentals/metric.png\", confidence=0.9)\n",
    "        first_pass = True\n",
    "    except pyautogui.ImageNotFoundException:\n",
    "        top_screenshot_boundary = pyautogui.locateOnScreen(\"assets/fundamentals/top_border.png\", confidence=0.9)\n",
    "    left = top_screenshot_boundary.left\n",
    "    top = top_screenshot_boundary.top + top_screenshot_boundary.height\n",
    "    width = 550\n",
    "    height = BOTTOM - top\n",
    "\n",
    "    screenshot = pyautogui.screenshot(region=(left, top, width, height))\n",
    "    screenshot = np.array(screenshot)\n",
    "\n",
    "    if first_pass:\n",
    "        title = pyautogui.locateOnScreen(\"assets/fundamentals/title.png\", confidence=0.9)\n",
    "        title_screenshot = pyautogui.screenshot(region=(left, title.top + title.height, title.width, title.height))\n",
    "        funds_date = extract_text(ocr, np.array(title_screenshot))\n",
    "    \n",
    "    text_list = extract_fundamentals_text(ocr, screenshot)\n",
    "    if text_list:\n",
    "        if len(text_list) <= 15:\n",
    "            return process_fundamentals(text_list, screenshot, ocr), ' '.join(funds_date)\n",
    "        else:\n",
    "            current_list = process_fundamentals(text_list, screenshot, ocr)\n",
    "            if prev_list:\n",
    "                if set(current_list) == set(prev_list):\n",
    "                    return current_list\n",
    "                return list(set(current_list + prev_list))\n",
    "            scroll(-999)\n",
    "            return extract_fundamentals(ocr, current_list), ' '.join(funds_date)\n",
    "    raise Exception('extract_fundamentals() error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remaining():\n",
    "    contract_details = load('data/contract_details.csv')\n",
    "    contract_details = sort_by_eur_exchanges(contract_details, drop=True)\n",
    "\n",
    "    root = 'data/fundamentals/'\n",
    "    dir_list = os.listdir(root)\n",
    "    this_month = datetime.now().strftime(\"%y-%m.csv\")\n",
    "    last_month = (datetime.now() - timedelta(days=32)).strftime(\"%y-%m.csv\")\n",
    "    dir_list = [file for file in dir_list if file.endswith(this_month) or file.endswith(last_month)]\n",
    "\n",
    "    if dir_list:\n",
    "        fundamental_dfs = []\n",
    "        for file in dir_list:\n",
    "            df = load(root + file)\n",
    "            df = df[df.apply(is_row_valid, axis=1)]\n",
    "            df['date_scraped'] = pd.to_datetime(df['date_scraped'])\n",
    "            df['days_since_last_scrape'] = (datetime.now() - df['date_scraped']).dt.days\n",
    "            fundamental_dfs.append(df)\n",
    "        final_df = pd.concat(fundamental_dfs)\n",
    "\n",
    "        # exclusion_condition = (final_df['exchange_bug'] == True) | ((final_df['exact_search'] == True) & (final_df['days_since_last_scrape'] <= 30))# | (~final_df['profile'].isna())\n",
    "        exclusion_condition = (final_df['exchange_bug'] == True) | (final_df['days_since_last_scrape'] <= 30) | (final_df['profile'].isna())\n",
    "        ids_to_exclude = final_df[exclusion_condition]['conId'].to_list()\n",
    "        bugged_ids = pd.read_csv(EXCHANGE_BUG_PATH)['conId'].to_list()\n",
    "        ids_to_exclude = list(set(bugged_ids) | set(ids_to_exclude))\n",
    "\n",
    "        remaining = contract_details[~contract_details['conId'].isin(ids_to_exclude)]\n",
    "\n",
    "        # # To debug invalid rows\n",
    "        # remaining = final_df.copy()\n",
    "        # remaining = remaining[~remaining.apply(is_row_valid, axis=1)]\n",
    "    else:\n",
    "        remaining = contract_details.copy()\n",
    "        \n",
    "    remaining = remaining[~remaining['longName'].apply(has_bad_multiplier)]\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(remaining, data_dict_list, wait_time):\n",
    "    global counter\n",
    "    exchange_bug = False\n",
    "    scrape_batch_iteration = 0\n",
    "\n",
    "    # for _, row in tqdm(remaining.sort_values(by='conId').iloc[::-1].iterrows(), total=len(remaining)):\n",
    "    # for _, row in tqdm(remaining.sort_values(by='conId').iterrows(),  total=len(remaining)):\n",
    "    # for _, row in tqdm(remaining.iloc[counter::-1].iterrows(), total=len(remaining)):\n",
    "    for _, row in tqdm(remaining.iloc[counter:].iterrows(), total=len(remaining)):\n",
    "        ocr = PaddleOCR()\n",
    "        profile, tradable, holding_types, top10, industries, countries, currencies, debtors, maturity, debt_type, fundamentals, lipper, style, funds_date = None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                search_exchange, search_symbol, exchange_bug = search_etf(ocr, row, wait_time)\n",
    "                exact_search = bool(search_symbol)\n",
    "            except Exception as e:\n",
    "                if e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                    raise Exception('manual')\n",
    "                \n",
    "                exchange_bug = quick_search_etf(row)\n",
    "                exact_search, search_symbol = False, None\n",
    "                search_symbol, search_exchange = check_title(ocr, str(row['symbol']))\n",
    "                if not search_exchange and not exchange_bug:\n",
    "                    counter += 1\n",
    "                    continue\n",
    "\n",
    "            if exchange_bug:\n",
    "                try:\n",
    "                    bugged = pd.read_csv(EXCHANGE_BUG_PATH)\n",
    "                    row_df = pd.DataFrame([row], columns=bugged.columns)\n",
    "                    bugged = pd.concat([bugged, row_df])\n",
    "                except FileNotFoundError:\n",
    "                    bugged = pd.DataFrame([row])\n",
    "                bugged.to_csv(EXCHANGE_BUG_PATH, index=False)\n",
    "                continue\n",
    "\n",
    "            # Overview\n",
    "            tradable = check_tradable(seconds=wait_time)\n",
    "            style = extract_style()\n",
    "            profile = extract_profile(ocr)\n",
    "            lipper = extract_lipper(ocr)\n",
    "            holding_types = extract_holding_types(ocr)\n",
    "\n",
    "            # Holdings tab\n",
    "            if select_tab('holdings', wait_time):\n",
    "                top10 = extract_top10(ocr)\n",
    "                industries = extract_industry(ocr)\n",
    "                countries = extract_country(ocr)\n",
    "                currencies = extract_currency(ocr)\n",
    "\n",
    "            # Bond data\n",
    "            try:\n",
    "                debtors = extract_debtors(ocr, 'debtor_quality')\n",
    "                maturity = extract_debtors(ocr, 'maturity')\n",
    "                debt_type = extract_debtors(ocr, 'debt_type')\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Ratios and Fundamentals tab\n",
    "            if select_tab('fundamentals', wait_time):\n",
    "                fundamentals, funds_date_str = extract_fundamentals(ocr)\n",
    "                funds_date = re.search(r'(\\d{1,2}/\\d{1,2}/\\d{4})', funds_date_str).group(1)\n",
    "                try:\n",
    "                    funds_date = datetime.strptime(funds_date, '%m/%d/%Y').strftime('%Y-%m-%d')\n",
    "                except ValueError as e:\n",
    "                    raise Exception(f\"Error parsing date '{funds_date}' from string '{funds_date_str}': {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if exchange_bug or e.args and len(e.args) > 0 and e.args[0] == 'skip':\n",
    "                pass\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'PyAutoGUI fail-safe triggered from mouse moving to a corner of the screen. To disable this fail-safe, set pyautogui.FAILSAFE to False. DISABLING FAIL-SAFE IS NOT RECOMMENDED.':\n",
    "                raise Exception('manual')\n",
    "            elif e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "                raise Exception('manual')\n",
    "            else:\n",
    "                traceback.print_exc()\n",
    "                print(f'\\nmain() {e} - Symbol: {row[\"symbol\"]} - Name: {row[\"longName\"]} - Exchange: {row[\"exchange\"]}\\n')\n",
    "                counter += 1\n",
    "                return\n",
    "\n",
    "        data_dict = {\n",
    "            'date_scraped': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'exchange_bug': exchange_bug,\n",
    "            'exact_search': exact_search,\n",
    "            'search_exchange': search_exchange,\n",
    "            'search_symbol': search_symbol,\n",
    "            'tradable': tradable,\n",
    "            'profile': profile,\n",
    "            'style': style,\n",
    "            'lipper': lipper,\n",
    "            'fundamentals': fundamentals,\n",
    "            'funds_date': funds_date,\n",
    "            'holding_types': holding_types,\n",
    "            'top10': top10,\n",
    "            'industries': industries,\n",
    "            'countries': countries,\n",
    "            'currencies': currencies,\n",
    "            'debtors': debtors,\n",
    "            'maturity': maturity,\n",
    "            'debt_type': debt_type,\n",
    "        }\n",
    "\n",
    "        row_dict = row.to_dict()\n",
    "        data_dict = {**row_dict, **data_dict}\n",
    "        data_dict_list.append(data_dict)\n",
    "        gc.collect()\n",
    "        if exchange_bug:\n",
    "            raise Exception(f'bug found')\n",
    "        scrape_batch_iteration += 1\n",
    "        if scrape_batch_iteration > 100:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Run main\n",
    "---\n",
    "1. Start Trader Workstation\n",
    "2. Set custom font size to 18 in settings\n",
    "3. Restart TW and open fundamental explorer\n",
    "4. Type in and load any instrument\n",
    "5. Minimize and maximize fundamental explorer window to fill the window width.\n",
    "6. Set keyboard input to qwerty US\n",
    "7. Now you can run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data_dict_list' in globals() and data_dict_list:\n",
    "    df = pd.DataFrame(data_dict_list)\n",
    "    backup = pd.concat([backup, df]).drop_duplicates(subset=['conId', 'funds_date'])\n",
    "    save(backup)\n",
    "backup = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['symbol'] == 'D5BB', 'countries'] = \"[('Germany', '98.84%'), ('Unidentified', '1.09%'), ('UnitedKingdom', '0.04%'), ('UnitedStates', '0%'), ('France', '0%'), ('Finland', '0%'), ('Netherlands', '0%'), ('Ireland', '0%'), ('Belgium', '0%'), ('Norway', '0%')]\"hljl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "counter = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        switch_to_app()\n",
    "        BOTTOM = 1070\n",
    "        SEARCH_RESULTS_ROW_HEIGHT = 21\n",
    "        EXCHANGE_BUG_PATH = 'data/fundamentals/exchange_bug.csv'\n",
    "        POSITIONS = {\n",
    "            'file': (82, 44),\n",
    "            'file_fund_option': (143, 120),\n",
    "            'maximize': (51, 40),\n",
    "            'search_box': (95, 44),\n",
    "            'dead_space': (1880, 100),\n",
    "        }\n",
    "        data_dict_list = []\n",
    "        remaining = get_remaining()\n",
    "        main(remaining, data_dict_list, wait_time=6)\n",
    "        df = pd.DataFrame(data_dict_list)\n",
    "        save(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(counter)\n",
    "        # traceback.print_exc()\n",
    "        if data_dict_list:\n",
    "            df = pd.DataFrame(data_dict_list)\n",
    "            backup = pd.concat([backup, df]).drop_duplicates(subset=['conId', 'funds_date'])\n",
    "            save(df)\n",
    "        else:\n",
    "            raise Exception('none found')\n",
    "        \n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'bug found':\n",
    "            print('bug found')\n",
    "            break\n",
    "        if e.args and len(e.args) > 0 and e.args[0] == 'manual':\n",
    "            print('manual')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Clean manually\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['top10', 'industries', 'countries', 'currencies', 'debtors', 'maturity', 'debt_type']\n",
    "mask = contracts_df['holding_types'].notna() & contracts_df[columns_to_check].isna().all(axis=1)\n",
    "bad_symbols = contracts_df[mask]['symbol'].to_list()\n",
    "bad_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'LSE',\n",
    "'FWB',\n",
    "'SBF',\n",
    "'AEB',\n",
    "'SWB',\n",
    "'WSE',\n",
    "'LJSE',\n",
    "'GETTEX',\n",
    "'CPH',\n",
    "'BUX',\n",
    "'VSE',\n",
    "'IBIS',\n",
    "'DXE',\n",
    "'AQXE',\n",
    "'AQXEUK',\n",
    "'AQXECH',\n",
    "'AQEUDE',\n",
    "'AQEUEN',\n",
    "'TRQX',\n",
    "'TRQXUK',\n",
    "'TRQXCH',\n",
    "'TRQXDE',\n",
    "'TRQXEN',\n",
    "'CHI-X',\n",
    "'BATE',\n",
    "'CHIXUK',\n",
    "'BATEUK',\n",
    "'CHIXCH',\n",
    "'BATECH',\n",
    "'CHIXDE',\n",
    "'BATEDE',\n",
    "'CHIXEN',\n",
    "'BATEEN',\n",
    "'EBS',\n",
    "'LSEETF',\n",
    "'TGATE',\n",
    "'BVME.ETF',\n",
    "'BM',\n",
    "'APEXEN',\n",
    "'TGHEEN',\n",
    "'IBEOS',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/fundamentals/'\n",
    "dir_list = os.listdir(root)\n",
    "this_month = datetime.now().strftime(\"%y-%m.csv\")\n",
    "last_month = (datetime.now() - timedelta(days=32)).strftime(\"%y-%m.csv\")\n",
    "dir_list = [file for file in dir_list if file.endswith(this_month) or file.endswith(last_month)]\n",
    "if dir_list:\n",
    "    fundamental_dfs = []\n",
    "    for file in dir_list:\n",
    "        df = load(root + file)\n",
    "        df = df[df.apply(is_row_valid, axis=1)]\n",
    "        df['date_scraped'] = pd.to_datetime(df['date_scraped'])\n",
    "        fundamental_dfs.append(df)\n",
    "    contracts_df = pd.concat(fundamental_dfs)\n",
    "\n",
    "contracts_df = clean_df(contracts_df)\n",
    "contracts_df = contracts_df[contracts_df.apply(is_row_valid, axis=1)]\n",
    "contracts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contracts_df = contracts_df[contracts_df['exact_search'] == False]\n",
    "# contracts_df = contracts_df[~contracts_df['symbol'].isin(bad_symbols)]\n",
    "# contracts_df = contracts_df[contracts_df['exchange_bug'] == True]\n",
    "contracts_df#.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual checks\n",
    "contracts_df = load('data/contract_elaborated.csv')\n",
    "contracts_df = clean_df(contracts_df)\n",
    "contracts_df = contracts_df[contracts_df.apply(is_row_valid, axis=1)]\n",
    "\n",
    "# 'profile', 'lipper', 'fundamentals', 'holding_types', 'dividends', 'top10', 'industries', 'countries', 'currencies', 'debtors', 'maturity', 'debt_type'\n",
    "column = 'debtors'\n",
    "\n",
    "filtered_column = contracts_df[column].dropna().tolist()\n",
    "\n",
    "# Extract elem[1] from all lists\n",
    "all_second_elements = []\n",
    "for fundamentals_list in filtered_column:\n",
    "    if isinstance(fundamentals_list, list):\n",
    "        for elem in fundamentals_list:\n",
    "            if isinstance(elem, tuple) and len(elem) > 1:\n",
    "                all_second_elements.append(elem[1]) # Set 1 to see values, 0 to see labels\n",
    "\n",
    "# Get unique values\n",
    "unique_labels = list(set(all_second_elements))\n",
    "unique_labels = list(set([elem if isinstance(elem, str) else 'NUMBSR' for elem in unique_labels])) # Check strings in values\n",
    "# unique_labels = list(set([elem if isinstance(elem, float) else np.nan for elem in unique_labels]))\n",
    "unique_labels.sort()\n",
    "unique_labels, len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similarity\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "strings = [s.strip('...') for s in unique_labels]\n",
    "strings = [re.sub(r'\\d+', '', s) for s in strings]\n",
    "\n",
    "unknown_terms = ['other', 'unknown', 'undefined', 'unidentified', 'other', 'noHolding', 'NotClassified', 'NotAvailable', '<NoCurrency>']\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "unknown_embeddings = model.encode(unknown_terms)\n",
    "\n",
    "classifications = []\n",
    "embeddings = model.encode(strings)\n",
    "similarities = cosine_similarity(embeddings, unknown_embeddings)\n",
    "max_similarities = np.max(similarities, axis=1)\n",
    "for s, max_sim in zip(strings, max_similarities):\n",
    "    if max_sim > 0.4:  # Threshold of 0.8\n",
    "        classifications.append((s, \"unknown\"))\n",
    "    else:\n",
    "        classifications.append((s, \"other\"))\n",
    "\n",
    "potential_unknowns = [s for s, cls in classifications if cls == \"unknown\"]\n",
    "potential_unknowns, len(potential_unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['AccountsPayable',\n",
    "'AccountsReceivable',\n",
    "'AccountsReceivable&Pay',\n",
    "'AdministrationFees',\n",
    "'CustodyFees',\n",
    "'ManagementFees',\n",
    "'OtherAssets',\n",
    "'OtherAssetsandLiabilities',\n",
    "'OtherAssetslessLiabilities',\n",
    "'OtherFees',\n",
    "'OtherLiabilities',\n",
    "'Tax',\n",
    "'Tax--ManagementFees']\n",
    "test = list(set(test))\n",
    "test.sort()\n",
    "test\n",
    "test = list(set(test))\n",
    "test.sort()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_labels = ['Equity', 'SalestoTotalAssetsLTDebt/Shareholders'] # Change manually\n",
    "\n",
    "splice = contracts_df[contracts_df[column].apply(lambda x: isinstance(x, list) and any(elem[0] in bad_labels or elem[0] == None or elem[0] == '' for elem in x))]\n",
    "symbols = splice['symbol'].to_list()\n",
    "bad_symbols += symbols\n",
    "# bad_symbols = symbols\n",
    "bad_symbols =  list(set(bad_symbols))\n",
    "display(splice[['symbol','exchange', 'primaryExchange', 'search_exchange', column]])\n",
    "print(len(bad_symbols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bad_symbols))\n",
    "\n",
    "contracts_df['lengths'] = contracts_df['fundamentals'].apply(lambda x: len(x) if isinstance(x, list) else np.nan)\n",
    "splice = contracts_df[(contracts_df['lengths'] != 5) & (contracts_df['lengths'] != 22)][['symbol', 'exchange', 'primaryExchange', 'lengths']]\n",
    "splice = splice[~splice['lengths'].isna()]\n",
    "symbols = splice['symbol'].to_list()\n",
    "bad_symbols += symbols\n",
    "bad_symbols =  list(set(bad_symbols))\n",
    "\n",
    "print(len(bad_symbols))\n",
    "## 22 or 5, sometimes 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
